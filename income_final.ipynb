{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Income Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.dirname(current_dir)\n",
    "\n",
    "file_path = os.path.join(data_dir, \"Statistics Canada\", \"incomes_quintile_hh.xlsx\")\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_comp_all\"] = np.log(df[\"comp_all\"])\n",
    "# Define independent (compx) and dependent (comp) variables\n",
    "compx = df[[\"log_comp_all\"]]  # Log of total income as independent variable\n",
    "\n",
    "# Add a constant term (intercept)\n",
    "compx = sm.add_constant(compx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quintile 1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q1   R-squared:                       0.903\n",
      "Model:                            OLS   Adj. R-squared:                  0.898\n",
      "Method:                 Least Squares   F-statistic:                     213.1\n",
      "Date:                Wed, 16 Apr 2025   Prob (F-statistic):           4.03e-13\n",
      "Time:                        08:35:25   Log-Likelihood:                 39.626\n",
      "No. Observations:                  25   AIC:                            -75.25\n",
      "Df Residuals:                      23   BIC:                            -72.81\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.4599      0.592      0.777      0.445      -0.765       1.685\n",
      "log_comp_all     0.7834      0.054     14.598      0.000       0.672       0.894\n",
      "==============================================================================\n",
      "Omnibus:                        5.668   Durbin-Watson:                   1.735\n",
      "Prob(Omnibus):                  0.059   Jarque-Bera (JB):                3.669\n",
      "Skew:                          -0.741   Prob(JB):                        0.160\n",
      "Kurtosis:                       4.152   Cond. No.                         637.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Quintile 2\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q2   R-squared:                       0.967\n",
      "Model:                            OLS   Adj. R-squared:                  0.965\n",
      "Method:                 Least Squares   F-statistic:                     663.7\n",
      "Date:                Wed, 16 Apr 2025   Prob (F-statistic):           1.82e-18\n",
      "Time:                        08:35:25   Log-Likelihood:                 47.834\n",
      "No. Observations:                  25   AIC:                            -91.67\n",
      "Df Residuals:                      23   BIC:                            -89.23\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.7618      0.427     -1.786      0.087      -1.644       0.121\n",
      "log_comp_all     0.9956      0.039     25.762      0.000       0.916       1.076\n",
      "==============================================================================\n",
      "Omnibus:                        3.421   Durbin-Watson:                   0.997\n",
      "Prob(Omnibus):                  0.181   Jarque-Bera (JB):                1.785\n",
      "Skew:                           0.516   Prob(JB):                        0.410\n",
      "Kurtosis:                       3.805   Cond. No.                         637.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Quintile 3\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q3   R-squared:                       0.985\n",
      "Model:                            OLS   Adj. R-squared:                  0.985\n",
      "Method:                 Least Squares   F-statistic:                     1555.\n",
      "Date:                Wed, 16 Apr 2025   Prob (F-statistic):           1.26e-22\n",
      "Time:                        08:35:25   Log-Likelihood:                 58.282\n",
      "No. Observations:                  25   AIC:                            -112.6\n",
      "Df Residuals:                      23   BIC:                            -110.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.2388      0.281     -0.850      0.404      -0.820       0.342\n",
      "log_comp_all     1.0034      0.025     39.435      0.000       0.951       1.056\n",
      "==============================================================================\n",
      "Omnibus:                        0.438   Durbin-Watson:                   1.282\n",
      "Prob(Omnibus):                  0.803   Jarque-Bera (JB):                0.226\n",
      "Skew:                           0.223   Prob(JB):                        0.893\n",
      "Kurtosis:                       2.870   Cond. No.                         637.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Quintile 4\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q4   R-squared:                       0.994\n",
      "Model:                            OLS   Adj. R-squared:                  0.993\n",
      "Method:                 Least Squares   F-statistic:                     3559.\n",
      "Date:                Wed, 16 Apr 2025   Prob (F-statistic):           1.01e-26\n",
      "Time:                        08:35:25   Log-Likelihood:                 68.032\n",
      "No. Observations:                  25   AIC:                            -132.1\n",
      "Df Residuals:                      23   BIC:                            -129.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.0307      0.190     -0.162      0.873      -0.424       0.363\n",
      "log_comp_all     1.0277      0.017     59.658      0.000       0.992       1.063\n",
      "==============================================================================\n",
      "Omnibus:                        5.405   Durbin-Watson:                   0.752\n",
      "Prob(Omnibus):                  0.067   Jarque-Bera (JB):                3.519\n",
      "Skew:                          -0.848   Prob(JB):                        0.172\n",
      "Kurtosis:                       3.709   Cond. No.                         637.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Quintile 5\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q5   R-squared:                       0.993\n",
      "Model:                            OLS   Adj. R-squared:                  0.993\n",
      "Method:                 Least Squares   F-statistic:                     3465.\n",
      "Date:                Wed, 16 Apr 2025   Prob (F-statistic):           1.38e-26\n",
      "Time:                        08:35:25   Log-Likelihood:                 68.441\n",
      "No. Observations:                  25   AIC:                            -132.9\n",
      "Df Residuals:                      23   BIC:                            -130.4\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.8483      0.187      4.535      0.000       0.461       1.235\n",
      "log_comp_all     0.9976      0.017     58.861      0.000       0.963       1.033\n",
      "==============================================================================\n",
      "Omnibus:                        0.376   Durbin-Watson:                   0.700\n",
      "Prob(Omnibus):                  0.828   Jarque-Bera (JB):                0.528\n",
      "Skew:                          -0.195   Prob(JB):                        0.768\n",
      "Kurtosis:                       2.404   Cond. No.                         637.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):  \n",
    "    quantile_col = f\"comp_q{i}\"\n",
    "    log_quantile_col = f\"log_comp_q{i}\"\n",
    "    \n",
    "    if quantile_col not in df.columns:\n",
    "        print(f\"Column {quantile_col} not found in DataFrame.\")\n",
    "        continue  # Skip if the column is missing\n",
    "\n",
    "    # Handle zero or negative values before log transformation\n",
    "    if (df[quantile_col] <= 0).any():\n",
    "        print(f\"Skipping {quantile_col} due to zero/negative values.\")\n",
    "        continue\n",
    "\n",
    "    # Compute log for the current quantile\n",
    "    df[log_quantile_col] = np.log(df[quantile_col])\n",
    "\n",
    "    # Define dependent variable (compy)\n",
    "    compy = df[log_quantile_col]\n",
    "    \n",
    "    # Run the regression\n",
    "    model = sm.OLS(compy, compx).fit()\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Quintile {i}\")\n",
    "    print(model.summary())\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Growth Rates for 2022 & 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate growth rates \n",
    "\n",
    "for i in range(1, 6):\n",
    "    df[f\"compq{i}_g\"] = df[f\"comp_q{i}\"].pct_change()\n",
    "    df[f\"tranrq{i}_g\"] = df[f\"tranr_q{i}\"].pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canada_compq1_2022: 0.012403379471508158\n",
      "canada_compq1_2023: 0.05779474431818188\n",
      "canada_compq2_2022: 0.039472560020505254\n",
      "canada_compq2_2023: 0.028740513438724413\n",
      "canada_compq3_2022: 0.06814698983580914\n",
      "canada_compq3_2023: 0.023233003454939283\n",
      "canada_compq4_2022: 0.07878008173149698\n",
      "canada_compq4_2023: 0.023342686776569588\n",
      "canada_compq5_2022: 0.07499350214843847\n",
      "canada_compq5_2023: 0.04678224188487068\n",
      "canada_tranrq1_2022: -0.0039343480507093576\n",
      "canada_tranrq1_2023: -0.006742738589211594\n",
      "canada_tranrq2_2022: -0.02424912235079968\n",
      "canada_tranrq2_2023: 0.004563928309680776\n",
      "canada_tranrq3_2022: -0.07645217869793997\n",
      "canada_tranrq3_2023: 0.04148357786549495\n",
      "canada_tranrq4_2022: -0.09942419799005753\n",
      "canada_tranrq4_2023: -0.012469719232754861\n",
      "canada_tranrq5_2022: -0.11292128324904449\n",
      "canada_tranrq5_2023: 0.06889198363652183\n"
     ]
    }
   ],
   "source": [
    "#store growth rates for 2022 and 2023 in a dictionary\n",
    "\n",
    "vars = ['compq1', 'compq2', 'compq3', 'compq4', 'compq5', 'tranrq1', 'tranrq2', 'tranrq3', 'tranrq4', 'tranrq5']\n",
    "growth_rates = {}  # Dictionary to store variable names and values\n",
    "\n",
    "for var in vars:\n",
    "    # Dynamically fetch values for 2022 and 2023 and assign them to keys in the dictionary\n",
    "    growth_rates[f'canada_{var}_2022'] = df.loc[df['year'] == 2022, f'{var}_g'].values[0]\n",
    "    growth_rates[f'canada_{var}_2023'] = df.loc[df['year'] == 2023, f'{var}_g'].values[0]\n",
    "\n",
    "# Now print the stored results from the dictionary\n",
    "for key, value in growth_rates.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import 2021 census, filter data\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.dirname(current_dir)\n",
    "\n",
    "file_path_census = os.path.join(data_dir, \"Statistics Canada\", \"Census 2021\", \"Hierarchical\", \"censush.csv\")\n",
    "census2021 = pd.read_csv(file_path_census)\n",
    "census2021 = census2021[census2021[\"PR\"] == 35]\n",
    "\n",
    "# Drop rows where income equals 88888888 (dropping NA values)\n",
    "census2021 = census2021[census2021[\"TOTINC\"] != 88888888]\n",
    "census2021 = census2021[census2021[\"MRKINC\"] != 88888888]\n",
    "census2021 = census2021[census2021[\"GTRFS\"] != 88888888]\n",
    "census2021 = census2021[census2021[\"TOTINC_AT\"] != 88888888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "wt_columns = [f\"WT{i}\" for i in range(1, 17)]\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"ABOID\", \"AGEIMM\", \"BFNMEMB\", \"BUILT\", \"CF_RP\", \"CFSTRUCT\", \"CIP2021\", \"CITIZEN\", \"CITOTH\",\n",
    "    \"CONDO\", \"COW\", \"DIST\", \"DTYPE\", \"EF_RP\", \"EFCOVID_ERB\", \"EFDECILE\", \"EFDIMBM_2018\", \"EMPIN\", \n",
    "    \"ETHDER\", \"FCOND\", \"FOL\", \"FPTWK\", \"GENDER\", \"GENSTAT\", \"HDGREE\", \"HLMOSTEN\", \n",
    "    \"HLMOSTFR\", \"HLMOSTNO\", \"HLREGEN\", \"HLREGFR\", \"HLREGNO\", \"HRSWRK\", \"INCTAX\", \"JOBPERM\", \"KOL\", \n",
    "   \"LI_ELIG_OML_U18\", \"LICO_AT\", \"LICO_BT\", \"LOC_ST_RES\", \"LOCSTUD\", \"LOLIMA\", \"LOLIMB\", \n",
    "    \"LOMBM_2018\", \"LSTWRK\", \"LWMOSTEN\", \"LWMOSTFR\", \"LWMOSTNO\", \"LWREGEN\", \"LWREGFR\", \"LWREGNO\", \n",
    "    \"MARSTH\", \"MOB1\", \"MOB5\", \"MODE\"\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "census2021 = census2021.drop(columns=wt_columns)\n",
    "census2021 = census2021.drop(columns=columns_to_drop, errors=\"ignore\")  # 'errors=\"ignore\"' ensures no error if a column is missing\n",
    "\n",
    "\n",
    "#set IMMSTAT = 1 if equal to 8\n",
    "census2021[\"IMMSTAT\"] = census2021[\"IMMSTAT\"].replace(8, 1)\n",
    "\n",
    "#create suitable bedroom variavle\n",
    "\n",
    "\n",
    "# Step 1: Define Household-Level Calculation\n",
    "def household_bedsuit(group):\n",
    "    num_couples = (group['CFSTAT'] == 1).sum() // 2 + (group['CFSTAT'] == 2).sum() // 2 # Couples share a room\n",
    "    num_single_parents = (group['CFSTAT'] == 3).sum()  # Each single parent gets a room\n",
    "    num_children = (group['CFSTAT'].isin([4, 5])).sum()  # Count children\n",
    "    num_non_family = (group['CFSTAT'].isin([7, 8])).sum()  # Each gets their own room\n",
    "    num_living_alone = (group['CFSTAT'] == 6).sum()  # People living alone\n",
    "\n",
    "    # If the household has exactly 1 person and they live alone â†’ Assign bedsuit = 0 (bachelor unit)\n",
    "    if len(group) == 1 and num_living_alone == 1:\n",
    "        return 0  \n",
    "\n",
    "    # Start with bedrooms for couples and single parents\n",
    "    bedrooms_needed = num_couples + num_single_parents\n",
    "\n",
    "    # Assign bedrooms for children: Every 2 children share 1 room\n",
    "    if num_children > 0:\n",
    "        bedrooms_needed += (num_children + 1) // 2  # Round up when odd number of children\n",
    "\n",
    "    # Add rooms for non-family members (CFSTAT = 7, 8)\n",
    "    bedrooms_needed += num_non_family\n",
    "\n",
    "    # If NOS == 1, ensure bedsuit does NOT exceed BEDRM\n",
    "    if 'NOS' in group.columns and group['NOS'].eq(1).any():  # Ensure 'NOS' exists\n",
    "        max_bedrooms = group['BEDRM'].dropna().max()  # Get the max BEDRM in household\n",
    "        if pd.notna(max_bedrooms):  \n",
    "            bedrooms_needed = min(bedrooms_needed, max_bedrooms)  # Ensure it doesn't exceed BEDRM\n",
    "\n",
    "    return bedrooms_needed\n",
    "\n",
    "# Step 2: **Initialize `bedsuit` column with NaN**\n",
    "census2021['bedsuit'] = pd.NA\n",
    "\n",
    "# Step 3: Apply household-level logic\n",
    "census2021['bedsuit'] = census2021.groupby('HH_ID')['bedsuit'].transform(\n",
    "    lambda x: household_bedsuit(census2021.loc[x.index])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create unemployment indicator\n",
    "def assign_econ(row):\n",
    "    if row['AGEGRP'] in [1, 2]:\n",
    "        return 3\n",
    "    elif 2 <= row['LFACT'] <= 10 and row['AGEGRP'] >= 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to create the ECON variable in census21\n",
    "census2021['econ'] = census2021.apply(assign_econ, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directory of the script (Model), then go up to Data\n",
    "data_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Build the full path to amr2021.xlsx\n",
    "file_path = os.path.join(data_dir, \"amr2021.xlsx\")\n",
    "\n",
    "\n",
    "#create a median market rent variable for Toronto/not-Toronto, by bedrooms for 2021\n",
    "amr2021 = pd.read_excel(file_path)\n",
    "# Perform a left join to add the MMR column to census2021\n",
    "census2021 = census2021.merge(amr2021, on=['bedsuit', 'CMA'], how='left')\n",
    "\n",
    "census2021['mmr'] = census2021['mmr'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with TOTINC > 88000000: 0\n",
      "Number of records with MRKINC > 88000000: 0\n",
      "Number of records with GTRFS > 88000000: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Correct missing values (children with no income)\n",
    "census2021.loc[census2021[\"TOTINC\"] > 88000000, \"TOTINC\"] = 0\n",
    "census2021.loc[census2021[\"MRKINC\"] > 88000000, \"MRKINC\"] = 0\n",
    "census2021.loc[census2021[\"GTRFS\"] > 88000000, \"GTRFS\"] = 0\n",
    "census2021.loc[census2021[\"TOTINC_AT\"] > 88000000, \"TOTINC_AT\"] = 0\n",
    "\n",
    "#check missing and NA values\n",
    "variables = [\"TOTINC\", \"MRKINC\", \"GTRFS\"]\n",
    "for var in variables:\n",
    "    count = (census2021[var] > 88000000).sum()\n",
    "    print(f\"Number of records with {var} > 88000000: {count}\")\n",
    "\n",
    "census2021[\"totaltransfers\"] = census2021[\"GTRFS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create quintiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HH_ID  TOTINC  quintile\n",
      "0      1   12000         1\n",
      "1      4   34000         4\n",
      "2      4   97000         4\n",
      "3      4       0         4\n",
      "4      4       0         4\n",
      "5      4       0         4\n",
      "6      6    3000         3\n",
      "7      6    8000         3\n",
      "8      6   69000         3\n",
      "9      6       0         3\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a new column for total income\n",
    "census2021[\"totalincome\"] = census2021[\"MRKINC\"] + census2021[\"GTRFS\"]\n",
    "\n",
    "# Step 2: Compute total household income (sum of MRKINC and GTRFS)\n",
    "household_income = census2021.groupby(\"HH_ID\").agg(\n",
    "    totalincome=(\"totalincome\", \"sum\"),  # Sum of the newly created totalincome\n",
    "    weight=(\"WEIGHT\", \"first\")  # Take first weight per household\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Step 3: Compute weighted quintiles\n",
    "def weighted_quantile(values, quantiles, sample_weight):\n",
    "    \"\"\"Calculate weighted quantiles for a given dataset.\"\"\"\n",
    "    sorter = np.argsort(values)\n",
    "    values, sample_weight = values[sorter], sample_weight[sorter]\n",
    "    weighted_cdf = np.cumsum(sample_weight) / np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_cdf, values)\n",
    "\n",
    "# Compute cutoff points for weighted quintiles\n",
    "quantile_cutoffs = weighted_quantile(\n",
    "    household_income[\"totalincome\"].values,\n",
    "    quantiles=[0.2, 0.4, 0.6, 0.8],\n",
    "    sample_weight=household_income[\"weight\"].values\n",
    ")\n",
    "\n",
    "# Step 4: Assign households to weighted quintiles\n",
    "household_income[\"quintile\"] = np.digitize(household_income[\"totalincome\"], bins=quantile_cutoffs, right=True) + 1\n",
    "\n",
    "# Step 5: Merge the quintile info back to the original dataset\n",
    "census2021 = census2021.merge(household_income[[\"HH_ID\", \"quintile\"]], on=\"HH_ID\", how=\"left\")\n",
    "\n",
    "# Step 6: Verify the result\n",
    "print(census2021[[\"HH_ID\", \"TOTINC\", \"quintile\"]].head(10))\n",
    "\n",
    "#subset census2021 for only quintiles 1 and 2\n",
    "census2021 = census2021[census2021[\"quintile\"].isin([1, 2, 3])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify transfer income shares using individual census file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIHM\n",
      "1    89550\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.dirname(current_dir)\n",
    "\n",
    "\n",
    "\n",
    "# import individual census file.\n",
    "file_path_censusi = os.path.join(data_dir, \"Statistics Canada\", \"Census 2021\", \"data_donnees_2021_ind.csv\")\n",
    "\n",
    "census2021i = pd.read_csv(file_path_censusi)\n",
    "\n",
    "census2021i = census2021i[census2021i[\"PR\"] == 35]\n",
    "census2021i = census2021i[census2021i[\"PRIHM\"] == 1]\n",
    "census2021i = census2021i[census2021i[\"HHInc\"] <= 25]\n",
    "\n",
    "#check how many rows have the different values of PRIHM\n",
    "print(census2021i[\"PRIHM\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to be dropped: 611\n",
      "Remaining rows: 88939\n",
      "Rows where 99999999 was replaced with 0: 88939\n",
      "    PPSORT  HHInc  GTRfs  COVID_ERB  CQPPB  EICBN  OASGI  CHDBN  GovtI  other\n",
      "8        9     25  13700      12100      0      0      0      0  13700   1600\n",
      "19      20     13  22800          0  12900      0   8700      0   1100   1200\n",
      "32      33     24  20100       8000      0   7300      0      0  12800   4800\n",
      "59      60     15   7600          0      0      0      0   5000   2600   2600\n",
      "74      75      8  17500          0      0      0      0      0  17500  17500\n",
      "    COVID_ERB_share  CQPPB_share  EICBN_share  OASGI_share  CHDBN_share  \\\n",
      "8          0.883212     0.000000     0.000000     0.000000     0.000000   \n",
      "19         0.000000     0.565789     0.000000     0.381579     0.000000   \n",
      "32         0.398010     0.000000     0.363184     0.000000     0.000000   \n",
      "59         0.000000     0.000000     0.000000     0.000000     0.657895   \n",
      "74         0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "\n",
      "    other_share  \n",
      "8      0.116788  \n",
      "19     0.052632  \n",
      "32     0.238806  \n",
      "59     0.342105  \n",
      "74     1.000000  \n",
      "q1_COVID_ERB_share: 0.18686854329434888\n",
      "q2_COVID_ERB_share: 0.22126406990521327\n",
      "q3_COVID_ERB_share: 0.2353531372491402\n",
      "q1_CQPPB_share: 0.22567433578874718\n",
      "q2_CQPPB_share: 0.2669406842417062\n",
      "q3_CQPPB_share: 0.2798693722936838\n",
      "q1_EICBN_share: 0.02927404990376784\n",
      "q2_EICBN_share: 0.04899242446682465\n",
      "q3_EICBN_share: 0.06462444969908586\n",
      "q1_OASGI_share: 0.28226937974462546\n",
      "q2_OASGI_share: 0.20436290481832545\n",
      "q3_OASGI_share: 0.18366452367774547\n",
      "q1_CHDBN_share: 0.04191546312872149\n",
      "q2_CHDBN_share: 0.08962677725118484\n",
      "q3_CHDBN_share: 0.09553112223872566\n",
      "q1_other_share: 0.23399822813978902\n",
      "q2_other_share: 0.16881313931674563\n",
      "q3_other_share: 0.14095739484161907\n",
      "Total q1 share (excluding COVID_ERB_share): 0.8131\n",
      "Total q2 share (excluding COVID_ERB_share): 0.7787\n",
      "Total q3 share (excluding COVID_ERB_share): 0.7646\n",
      "q1_CQPPB_share_n: 0.2775\n",
      "q2_CQPPB_share_n: 0.3428\n",
      "q3_CQPPB_share_n: 0.3660\n",
      "q1_EICBN_share_n: 0.0360\n",
      "q2_EICBN_share_n: 0.0629\n",
      "q3_EICBN_share_n: 0.0845\n",
      "q1_OASGI_share_n: 0.3471\n",
      "q2_OASGI_share_n: 0.2624\n",
      "q3_OASGI_share_n: 0.2402\n",
      "q1_CHDBN_share_n: 0.0515\n",
      "q2_CHDBN_share_n: 0.1151\n",
      "q3_CHDBN_share_n: 0.1249\n",
      "q1_other_share_n: 0.2878\n",
      "q2_other_share_n: 0.2168\n",
      "q3_other_share_n: 0.1843\n"
     ]
    }
   ],
   "source": [
    "# for columns HHInc,GTRfs, COVID_ERB, CQPPB, EICBN, OASGI, CHDBN, GovtI,  set values greater than 88000000 equal to 0\n",
    "columns_to_fix = [\"HHInc\", \"GTRfs\", \"COVID_ERB\", \"CQPPB\", \"EICBN\", \"OASGI\", \"CHDBN\", \"GovtI\"]\n",
    "\n",
    "# Identify rows where any of the specified columns has a value of 88888888\n",
    "rows_to_drop = census2021i[census2021i[columns_to_fix].eq(88888888).any(axis=1)]\n",
    "\n",
    "# Print how many rows will be dropped\n",
    "print(f\"Rows to be dropped: {len(rows_to_drop)}\")\n",
    "\n",
    "# Drop those rows from the DataFrame\n",
    "census2021i = census2021i.drop(rows_to_drop.index)\n",
    "\n",
    "# Optionally, confirm the rows are dropped (this will show the remaining rows)\n",
    "print(f\"Remaining rows: {len(census2021i)}\")\n",
    "\n",
    "# Replace 99999999 with 0 in the specified columns\n",
    "census2021i[columns_to_fix] = census2021i[columns_to_fix].replace(99999999, 0)\n",
    "\n",
    "# Verify if the replacement is successful\n",
    "rows_to_check = census2021i[census2021i[columns_to_fix].eq(0).any(axis=1)]\n",
    "print(f\"Rows where 99999999 was replaced with 0: {len(rows_to_check)}\")\n",
    "\n",
    "#create a variable that is equal to GTRfs - COVID_ERB - CQPPB - EICBN - OASGI-CHDBN-Govtl\n",
    "census2021i[\"other\"] = census2021i[\"GTRfs\"] - census2021i[\"COVID_ERB\"] - census2021i[\"CQPPB\"] - census2021i[\"EICBN\"] - census2021i[\"OASGI\"] - census2021i[\"CHDBN\"]\n",
    "\n",
    "# Display the head of census2021i with specified columns\n",
    "print(census2021i[['PPSORT', 'HHInc', 'GTRfs', 'COVID_ERB', 'CQPPB', 'EICBN', 'OASGI', 'CHDBN', 'GovtI', 'other']].head())\n",
    "\n",
    "# Define the columns to compute as share of GTRfs\n",
    "share_columns = [\"COVID_ERB\", \"CQPPB\", \"EICBN\", \"OASGI\", \"CHDBN\", \"other\"]\n",
    "\n",
    "# Calculate share of each column as a percentage of GTRfs\n",
    "for column in share_columns:\n",
    "    # Check if the column exists to avoid errors\n",
    "    if column in census2021i.columns and \"GTRfs\" in census2021i.columns:\n",
    "        census2021i[f\"{column}_share\"] = census2021i[column] / census2021i[\"GTRfs\"]\n",
    "    else:\n",
    "        print(f\"Column {column} or GTRfs not found in the dataframe\")\n",
    "\n",
    "# Print the new columns to verify\n",
    "print(census2021i[[\"COVID_ERB_share\", \"CQPPB_share\", \"EICBN_share\", \"OASGI_share\", \"CHDBN_share\", \"other_share\"]].head())\n",
    "\n",
    "# Define income groups\n",
    "low_income = census2021i[\"HHInc\"] < 14\n",
    "mid_income = (census2021i[\"HHInc\"] >= 14) & (census2021i[\"HHInc\"] <= 19)\n",
    "high_income = census2021i[\"HHInc\"] >19\n",
    "\n",
    "# Function to compute weighted shares for a subset of the dataset and save them to individual variables\n",
    "def compute_weighted_shares(df, label, prefix):\n",
    "    weighted_sum_GTRfs = (df[\"GTRfs\"] * df[\"WEIGHT\"]).sum()\n",
    "    \n",
    "    for column in share_columns:\n",
    "        if column in df.columns and \"GTRfs\" in df.columns:\n",
    "            weighted_sum_column = (df[column] * df[\"WEIGHT\"]).sum()\n",
    "            share = weighted_sum_column / weighted_sum_GTRfs if weighted_sum_GTRfs != 0 else 0\n",
    "            # Create individual variables and assign the computed share values\n",
    "            globals()[f\"{prefix}_{column}_share\"] = share\n",
    "        else:\n",
    "            print(f\"Column {column} or GTRfs not found in the dataframe for {label}\")\n",
    "\n",
    "# Compute for low-income group\n",
    "compute_weighted_shares(census2021i[low_income], \"HHInc < 44,000\", \"q1\")\n",
    "\n",
    "# Compute for mid-income group\n",
    "compute_weighted_shares(census2021i[mid_income], \"HHInc 44,001 - 74,000\", \"q2\")\n",
    "\n",
    "# Compute for high-income group\n",
    "compute_weighted_shares(census2021i[high_income], \"HHInc 74,000 - 110,000\", \"q3\")\n",
    "\n",
    "for column in share_columns:\n",
    "    # Print variables for low-income group (q1)\n",
    "    q1_share_value = globals().get(f'q1_{column}_share', 'Not Defined')\n",
    "    print(f\"q1_{column}_share: {q1_share_value}\")\n",
    "    \n",
    "    # Print variables for mid-income group (q2)\n",
    "    q2_share_value = globals().get(f'q2_{column}_share', 'Not Defined')\n",
    "    print(f\"q2_{column}_share: {q2_share_value}\")\n",
    "\n",
    "      # Print variables for high-income group (q3)\n",
    "    q3_share_value = globals().get(f'q3_{column}_share', 'Not Defined')\n",
    "    print(f\"q3_{column}_share: {q3_share_value}\")\n",
    "\n",
    "# Sum all q1 shares excluding q1_COVID_ERB_share\n",
    "q1_total_share = 0\n",
    "for column in share_columns:\n",
    "    if column != \"COVID_ERB\":  # Exclude q1_COVID_ERB_share\n",
    "        q1_total_share += globals().get(f'q1_{column}_share', 0)\n",
    "\n",
    "# Sum all q2 shares excluding q2_COVID_ERB_share\n",
    "q2_total_share = 0\n",
    "for column in share_columns:\n",
    "    if column != \"COVID_ERB\":  # Exclude q2_COVID_ERB_share\n",
    "        q2_total_share += globals().get(f'q2_{column}_share', 0)\n",
    "\n",
    "# Sum all q3 shares excluding q3_COVID_ERB_share\n",
    "q3_total_share = 0\n",
    "for column in share_columns:\n",
    "    if column != \"COVID_ERB\":  # Exclude q3_COVID_ERB_share\n",
    "        q3_total_share += globals().get(f'q3_{column}_share', 0)\n",
    "\n",
    "\n",
    "# Print the total sums for q1 and q2 and q3 (excluding COVID_ERB share)\n",
    "print(f\"Total q1 share (excluding COVID_ERB_share): {q1_total_share:.4f}\")\n",
    "print(f\"Total q2 share (excluding COVID_ERB_share): {q2_total_share:.4f}\")\n",
    "print(f\"Total q3 share (excluding COVID_ERB_share): {q3_total_share:.4f}\")\n",
    "\n",
    "# Define and normalize q1 and q2 share values\n",
    "for column in share_columns:\n",
    "    if column != \"COVID_ERB\":\n",
    "        # Get the share values for q1 and q2 and q3\n",
    "        q1_share = globals().get(f'q1_{column}_share', 0)\n",
    "        q2_share = globals().get(f'q2_{column}_share', 0)\n",
    "        q3_share = globals().get(f'q3_{column}_share', 0)\n",
    "        \n",
    "        # Calculate the total for q1 and q2 and q3 (excluding COVID_ERB share)\n",
    "        q1_total_share = sum(globals().get(f'q1_{col}_share', 0) for col in share_columns if col != \"COVID_ERB\")\n",
    "        q2_total_share = sum(globals().get(f'q2_{col}_share', 0) for col in share_columns if col != \"COVID_ERB\")\n",
    "        q3_total_share = sum(globals().get(f'q3_{col}_share', 0) for col in share_columns if col != \"COVID_ERB\")\n",
    "        \n",
    "        # Normalize the share values\n",
    "        q1_normalized_value = q1_share / q1_total_share if q1_total_share != 0 else 0\n",
    "        q2_normalized_value = q2_share / q2_total_share if q2_total_share != 0 else 0\n",
    "        q3_normalized_value = q3_share / q3_total_share if q3_total_share != 0 else 0\n",
    "        \n",
    "        # Store the normalized share values in the globals() dictionary\n",
    "        globals()[f'q1_{column}_share_n'] = q1_normalized_value\n",
    "        globals()[f'q2_{column}_share_n'] = q2_normalized_value\n",
    "        globals()[f'q3_{column}_share_n'] = q3_normalized_value\n",
    "        \n",
    "        # Print the normalized share values\n",
    "        print(f\"q1_{column}_share_n: {q1_normalized_value:.4f}\")\n",
    "        print(f\"q2_{column}_share_n: {q2_normalized_value:.4f}\")\n",
    "        print(f\"q3_{column}_share_n: {q3_normalized_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 2021 Core Housing Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Aggregate total household income\n",
    "household_income2 = census2021.groupby('HH_ID')['totalincome'].sum().reset_index()\n",
    "\n",
    "# Step 2: Merge back into census2021\n",
    "census2021 = census2021.merge(household_income2, on='HH_ID', suffixes=('', '_hh'))\n",
    "\n",
    "\n",
    "# identify households where every preson in unrelated or living alone\n",
    "household_non_family = census2021.groupby('HH_ID')['CFSTAT'].apply(lambda x: set(x).issubset({6, 7})).reset_index()\n",
    "household_non_family.columns = ['HH_ID', 'non_family_household']\n",
    "household_non_family['non_family_household'] = household_non_family['non_family_household'].astype(int)\n",
    "\n",
    "#merge back into census2021\n",
    "census2021 = census2021.merge(household_non_family, on='HH_ID', how='left')\n",
    "\n",
    "#Identify households where at least one maintainer (HHMAINP == 1) is aged 15-29 and attending school\n",
    "maintainers = census2021[(census2021['HHMAINP'] == 1) & \n",
    "                         (census2021['AGEGRP'].isin([3, 4, 5])) & \n",
    "                         (census2021['ATTSCH'] == 1)]\n",
    "\n",
    "excluded_households = maintainers['HH_ID'].unique()\n",
    "census2021['student_household'] = census2021['HH_ID'].isin(excluded_households).astype(int) # 1 if student, 0 otherwise\n",
    "\n",
    "# Step 3: Define Core Housing Need (CHN)\n",
    "census2021['chn'] = 0  # Default to 0 (not in CHN)\n",
    "\n",
    "# Condition: Housing is unaffordable OR unsuitable OR inadequate\n",
    "housing_issue = (\n",
    "    (census2021['SHELCO'] * 12 / census2021['totalincome_hh'] > 0.30) |  # Unaffordable\n",
    "    (census2021['NOS'] == 0) |  # Unsuitable\n",
    "    (census2021['REPAIR'] == 3)  # Inadequate\n",
    ")\n",
    "\n",
    "# Condition: Alternative market rent is also unaffordable\n",
    "market_unaffordable = (census2021['mmr']) * 12 > 0.30 * census2021['totalincome_hh']\n",
    "\n",
    "# Set Core Housing Need (CHN) variable, excluding non-family households with an eligible maintainer\n",
    "census2021.loc[housing_issue & market_unaffordable & \n",
    "               ~((census2021['student_household'] == 1) & (census2021['non_family_household'] == 1)), \n",
    "               'chn'] = 1\n",
    "\n",
    "\n",
    "# Create STIR (Shelter Cost to Income Ratio)\n",
    "census2021[\"stir\"] = (census2021[\"SHELCO\"] * 12) / census2021[\"totalincome_hh\"]\n",
    "\n",
    "# Create ALTSTIR (Alternative STIR using AMR)\n",
    "census2021[\"altstir\"] = (census2021[\"mmr\"] * 12) / census2021[\"totalincome_hh\"]\n",
    "\n",
    "# Update CHN: Exclude individuals with STIR >= 1\n",
    "census2021.loc[census2021[\"stir\"] >= 1, \"chn\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Define Deep Core Housing Need (DCHN)\n",
    "census2021['dchn'] = 0  # Default to 0\n",
    "\n",
    "deep_housing_issue = (\n",
    "    (census2021['SHELCO'] * 12 / census2021['totalincome_hh'] > 0.50) |  # Deeply unaffordable\n",
    "    (census2021['NOS'] == 0) |  # Unsuitable\n",
    "    (census2021['REPAIR'] == 3)  # Inadequate\n",
    ")\n",
    "\n",
    "deep_market_unaffordable = (census2021['mmr']) * 12 > 0.50 * census2021['totalincome_hh']\n",
    "\n",
    "# Apply DCHN flag with same exclusions\n",
    "census2021.loc[deep_housing_issue & deep_market_unaffordable &\n",
    "               ~((census2021['student_household'] == 1) & (census2021['non_family_household'] == 1)), \n",
    "               'dchn'] = 1\n",
    "\n",
    "# Update DCHN: Exclude individuals with STIR >= 1\n",
    "census2021.loc[census2021[\"stir\"] >= 1, \"dchn\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "census2022 = census2021.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Load the population projection file\n",
    "file_path_pop = os.path.join(data_dir, \"popproj.xlsx\")\n",
    "popproj = pd.read_excel(file_path_pop)\n",
    "\n",
    "# Filter to 2022 growth rates only\n",
    "growth_rates_2022 = popproj[['demo', 'agegrp', 'econ', 2022]]\n",
    "\n",
    "# Create a lookup dictionary: {(agegrp, demo, econ): growth_rate}\n",
    "growth_rate_lookup = {\n",
    "    (row['agegrp'], row['demo'], row['econ']): row[2022]\n",
    "    for _, row in growth_rates_2022.iterrows()\n",
    "}\n",
    "\n",
    "# Define the AGEGRP mapping from numbers to labels\n",
    "agegrp_mapping = {\n",
    "    1: '0to9',\n",
    "    2: '10to14',\n",
    "    3: '15to19',\n",
    "    4: '20to24',\n",
    "    5: '25to29',\n",
    "    6: '30to34',\n",
    "    7: '35to39',\n",
    "    8: '40to44',\n",
    "    9: '45to49',\n",
    "    10: '50to54',\n",
    "    11: '55to64',\n",
    "    12: '65to74',\n",
    "    13: '75plus',\n",
    "    88: \"total\"\n",
    "}\n",
    "\n",
    "# Function to apply growth rates based on AGEGRP, IMMSTAT, and ECON\n",
    "def apply_growth(row):\n",
    "    agegrp_code = row['AGEGRP']\n",
    "    immstat = row['IMMSTAT']\n",
    "    econ = row['econ']\n",
    "\n",
    "    # Map AGEGRP code to string label\n",
    "    agegrp_label = agegrp_mapping.get(agegrp_code, None)\n",
    "    \n",
    "    if agegrp_label is None:\n",
    "        print(f\"Warning: Unknown AGEGRP code {agegrp_code} in row {row.name}\")\n",
    "        return row  # Skip updating this row\n",
    "\n",
    "    # Determine if the person is NPR or non-NPR based on IMMSTAT\n",
    "    demo = 'npr' if immstat == 3 else 'nonnpr'\n",
    "    \n",
    "    # Lookup the growth rate, defaulting to 1 if not found\n",
    "    growth_rate = growth_rate_lookup.get((agegrp_label, demo, econ), 1)\n",
    "    \n",
    "    # Apply the growth rate\n",
    "    row['WEIGHT'] *= (1 + growth_rate)\n",
    "    return row\n",
    "\n",
    "# Apply the updated growth function to census2022\n",
    "census2022 = census2022.apply(apply_growth, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary statistics:\n",
    "income quintile ranges\n",
    "number of households per quintile\n",
    "number of household in CHN per quintile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             min      max\n",
      "quintile                 \n",
      "1         -38300    44300\n",
      "2          44301    74500\n",
      "3          74501   109900\n",
      "4         110000   162101\n",
      "5         162200  1613152\n",
      "quintile\n",
      "1    1,104,493\n",
      "2    1,104,192\n",
      "3    1,102,284\n",
      "Name: WEIGHT, dtype: object\n",
      "Total households (weighted): 3,310,969\n"
     ]
    }
   ],
   "source": [
    "# Show the min and max household income for each quintile\n",
    "print(household_income.groupby(\"quintile\")[\"totalincome\"].agg([\"min\", \"max\"]))\n",
    "\n",
    "# Step 1: Aggregate weights at the household level\n",
    "household_weights = census2021.groupby(\"HH_ID\")[\"WEIGHT\"].first().reset_index()\n",
    "\n",
    "# Step 2: Merge back the quintile information\n",
    "household_weights = household_weights.merge(\n",
    "    household_income[[\"HH_ID\", \"quintile\"]], on=\"HH_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Step 3: Compute weighted household counts by quintile\n",
    "household_weighted_counts = household_weights.groupby(\"quintile\")[\"WEIGHT\"].sum()\n",
    "\n",
    "# Print results with comma separators\n",
    "print(household_weighted_counts.apply(lambda x: f\"{x:,.0f}\"))\n",
    "\n",
    "# Sum total weights across all households\n",
    "total_weight = household_weighted_counts.sum()\n",
    "print(f\"Total households (weighted): {total_weight:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quintile\n",
      "1    467,645\n",
      "2    166,994\n",
      "3      5,824\n",
      "Name: WEIGHT, dtype: object\n",
      "640463.50217058\n"
     ]
    }
   ],
   "source": [
    "# Keep one row per household in core housing need\n",
    "core_housing_need_households = (\n",
    "    census2021[census2021[\"HCORENEED_IND\"] == 100]\n",
    "    .drop_duplicates(subset=\"HH_ID\")\n",
    ")\n",
    "\n",
    "# Sum of household weights by quintile\n",
    "core_housing_need_weighted = (\n",
    "    core_housing_need_households.groupby(\"quintile\")[\"WEIGHT\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# Format numbers with comma separators\n",
    "print(core_housing_need_weighted.apply(lambda x: f\"{x:,.0f}\"))\n",
    "\n",
    "#print sum of households in core housing need\n",
    "total_core_housing_need = core_housing_need_weighted.sum()\n",
    "print(total_core_housing_need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grow market income for 2022 based on Canada quintile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_mrkinc(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq1_2022'])\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq2_2022'])\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq3_2022'])\n",
    "    elif row['quintile'] == 4:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq4_2022'])\n",
    "    elif row['quintile'] == 5:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq5_2022'])\n",
    "    else:\n",
    "        return row['MRKINC']  # Default case if quintile is missing\n",
    "\n",
    "# Apply function row-wise\n",
    "census2022.loc[:, 'MRKINC'] = census2022.apply(adjust_mrkinc, axis=1).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grow transfer income for 2022 based on Canada quintile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gtrfs(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq1_2022'])\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq2_2022'])\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq3_2022'])\n",
    "    else:\n",
    "        return row['GTRFS']  # Default case if quintile is missing\n",
    "\n",
    "# Apply function row-wise\n",
    "census2022.loc[:, 'GTRFS'] = census2022.apply(adjust_gtrfs, axis=1).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new variable for total income (after growing MRKINC and GTRFS)\n",
    "census2022[\"totalincome\"] = census2022[\"MRKINC\"] + census2022[\"GTRFS\"]\n",
    "census2022[\"totaltransfers\"] = census2022[\"GTRFS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grow 2022 shelco based on tenur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SHELCO     mmr\n",
      "0   200.0   900.0\n",
      "1   800.0  1700.0\n",
      "2   800.0  1700.0\n",
      "3   800.0  1700.0\n",
      "4   800.0  1700.0\n"
     ]
    }
   ],
   "source": [
    "print(census2022[['SHELCO', 'mmr']].head()) #check values before growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year      rent  mortgage  othercosts\n",
      "0  2022  0.052632  0.080999    0.034682\n",
      "1  2023  0.071429  0.118275    0.067737\n",
      "2  2024  0.053333  0.039265    0.037933\n",
      "3  2025  0.051074  0.027718    0.023945\n",
      "4  2026  0.051079  0.036965    0.020308\n",
      "       SHELCO     mmr\n",
      "0  210.526316   900.0\n",
      "1  827.745665  1700.0\n",
      "2  827.745665  1700.0\n",
      "3  827.745665  1700.0\n",
      "4  827.745665  1700.0\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.dirname(current_dir)\n",
    "\n",
    "\n",
    "file_path_growth = os.path.join(data_dir, \"growthrates.xlsx\")\n",
    "growth = pd.read_excel(file_path_growth)\n",
    "\n",
    "print(growth.head())\n",
    "\n",
    "#increase shelco variable by the 2022 rent variable in the growth df, if tenur is 2, increase by the mortgage variable if tenur is 1\n",
    "\n",
    "year_to_use = 2022 \n",
    "\n",
    "def adjust_shelco(row):\n",
    "    rent = growth.loc[growth['year'] == year_to_use, 'rent'].values[0]\n",
    "    mortgage = growth.loc[growth['year'] == year_to_use, 'mortgage'].values[0]\n",
    "    othercosts = growth.loc[growth['year'] == year_to_use, 'othercosts'].values[0]\n",
    "\n",
    "    if row['TENUR'] == 2:  # Renters\n",
    "        return row['SHELCO'] * (1 + rent)\n",
    "    elif row['TENUR'] == 1:\n",
    "        if row['PRESMORTG'] in [1, 8]:  # Mortgage holders\n",
    "            return row['SHELCO'] * (1 + mortgage)\n",
    "        elif row['PRESMORTG'] == 0:  # No mortgage, use othercosts\n",
    "            return row['SHELCO'] * (1 + othercosts)\n",
    "    \n",
    "    # Default case\n",
    "    return row['SHELCO'] * (1 + rent)\n",
    "#assigns unknown TENUR to renters\n",
    "\n",
    "# Apply\n",
    "census2022['SHELCO'] = census2022.apply(adjust_shelco, axis=1)\n",
    "print(census2022[['SHELCO', 'mmr']].head())  # Check values after growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SHELCO          mmr\n",
      "0  210.526316   947.368421\n",
      "1  827.745665  1789.473684\n",
      "2  827.745665  1789.473684\n",
      "3  827.745665  1789.473684\n",
      "4  827.745665  1789.473684\n"
     ]
    }
   ],
   "source": [
    "#increase mmr variable by the 2022 rent variable in the growth df\n",
    "census2022['mmr'] = census2022['mmr']*(1+growth.loc[growth['year'] == year_to_use, 'rent'].values[0])\n",
    "print(census2022[['SHELCO', 'mmr']].head()) #check values after growing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create 2023 census df, apply market and transfer income growth rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HH_ID     PP_ID   TOTINC  quintile\n",
      "0    1.0   11101.0  12000.0       1.0\n",
      "1    6.0   61101.0   3000.0       3.0\n",
      "2    6.0   61102.0   8000.0       3.0\n",
      "3    6.0   61103.0  69000.0       3.0\n",
      "4    6.0   61104.0      0.0       3.0\n",
      "5   13.0  131101.0  63000.0       3.0\n",
      "6   13.0  131102.0  41000.0       3.0\n",
      "7   13.0  131103.0      0.0       3.0\n",
      "8   13.0  131104.0      0.0       3.0\n",
      "9   15.0  151101.0   5000.0       1.0\n"
     ]
    }
   ],
   "source": [
    "# Creating 2023 microsimulation\n",
    "census2023 = census2022.copy()\n",
    "\n",
    "# Verify the result\n",
    "print(census2023[[\"HH_ID\", \"PP_ID\", \"TOTINC\", \"quintile\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adj weights for pop growth\n",
    "# Filter to 2023 growth rates, now including 'econ'\n",
    "growth_rates_2023 = popproj[['demo', 'agegrp', 'econ', 2023]]\n",
    "\n",
    "# Create the 2023 growth rate lookup dictionary\n",
    "growth_rate_lookup_2023 = {\n",
    "    (row['agegrp'], row['demo'], row['econ']): row[2023]\n",
    "    for _, row in growth_rates_2023.iterrows()\n",
    "}\n",
    "\n",
    "# Apply the 2023 growth rates\n",
    "def apply_growth_2023(row):\n",
    "    agegrp_code = row['AGEGRP']\n",
    "    immstat = row['IMMSTAT']\n",
    "    econ = row['econ']  # Include ECON in the logic\n",
    "\n",
    "    agegrp_label = agegrp_mapping.get(agegrp_code, None)\n",
    "    \n",
    "    if agegrp_label is None:\n",
    "        print(f\"Warning: Unknown AGEGRP code {agegrp_code} in row {row.name}\")\n",
    "        return row  # Skip updating this row\n",
    "\n",
    "    demo = 'npr' if immstat == 3 else 'nonnpr'\n",
    "    \n",
    "    # Lookup the growth rate, defaulting to 1 if not found\n",
    "    growth_rate = growth_rate_lookup_2023.get((agegrp_label, demo, econ), 1)\n",
    "    \n",
    "    row['WEIGHT'] *= (1 + growth_rate)\n",
    "    return row\n",
    "\n",
    "# Apply the updated function to census2023\n",
    "census2023 = census2023.apply(apply_growth_2023, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_mrkinc(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq1_2023'])\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq2_2023'])\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq3_2023'])\n",
    "    elif row['quintile'] == 4:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq4_2023'])\n",
    "    elif row['quintile'] == 5:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq5_2023'])\n",
    "    else:\n",
    "        return row['MRKINC']  # Default case if quintile is missing\n",
    "\n",
    "# Apply function row-wise\n",
    "census2023.loc[:, 'MRKINC'] = census2023.apply(adjust_mrkinc, axis=1).astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gtrfs(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq1_2023'])\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq2_2023'])\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq3_2023'])\n",
    "    elif row['quintile'] == 4:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq4_2023'])\n",
    "    elif row['quintile'] == 5:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq5_2023'])\n",
    "    else:\n",
    "        return row['GTRFS']  # Default case if quintile is missing\n",
    "\n",
    "# Apply function row-wise\n",
    "census2023.loc[:, 'GTRFS'] = census2023.apply(adjust_gtrfs, axis=1).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new variable for total income (after growing MRKINC and GTRFS)\n",
    "census2023[\"totalincome\"] = census2023[\"MRKINC\"] + census2023[\"GTRFS\"]\n",
    "census2023[\"totaltransfers\"] = census2023[\"GTRFS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2023 census, split out transfer income into subcategories, using shares calculated earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target columns and their corresponding share names\n",
    "share_mapping = {\n",
    "    \"cpp\": \"CQPPB_share_n\",\n",
    "    \"ei\": \"EICBN_share_n\",\n",
    "    \"oas\": \"OASGI_share_n\",\n",
    "    \"child\": \"CHDBN_share_n\",\n",
    "    \"social\": \"other_share_n\"\n",
    "}\n",
    "\n",
    "# Loop over quintiles 1 to 3\n",
    "for quintile in [1, 2, 3]:\n",
    "    for column, share_name in share_mapping.items():\n",
    "        # Build the variable name, e.g., 'q1_CQPPB_share_n'\n",
    "        variable_name = f'q{quintile}_{share_name}'\n",
    "        share_value = globals().get(variable_name, None)\n",
    "        \n",
    "        if share_value is None:\n",
    "            print(f\"Error: {variable_name} is not defined.\")\n",
    "        else:\n",
    "            census2023.loc[census2023[\"quintile\"] == quintile, column] = share_value * census2023[\"GTRFS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SHELCO          mmr\n",
      "0  225.563910  1015.037594\n",
      "1  883.815029  1917.293233\n",
      "2  883.815029  1917.293233\n",
      "3  883.815029  1917.293233\n",
      "4  883.815029  1917.293233\n"
     ]
    }
   ],
   "source": [
    "#update shelco & mmr for 2023\n",
    "\n",
    "year_to_use = 2023  \n",
    "\n",
    "census2023['SHELCO'] = census2023.apply(adjust_shelco, axis=1)\n",
    "census2023['mmr'] = census2023['mmr']*(1+growth.loc[growth['year'] == year_to_use, 'rent'].values[0])\n",
    "print(census2023[['SHELCO', 'mmr']].head())  # Check values after growing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Microsimulations for 2021-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved census data for 2021 to ../Microsimulations/census2021.csv\n",
      "Saved census data for 2022 to ../Microsimulations/census2022.csv\n",
      "Saved census data for 2023 to ../Microsimulations/census2023.csv\n"
     ]
    }
   ],
   "source": [
    "#Export Census data (2021 to 2023) to .csv\n",
    "folder_path = \"../Microsimulations\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "census_years = [2021, 2022, 2023]\n",
    "\n",
    "# Loop through each year and save the corresponding census dataset\n",
    "for year in census_years:\n",
    "    # Dynamically create the census variable name based on the year\n",
    "    census = globals().get(f\"census{year}\", None)\n",
    "    \n",
    "    if census is not None:\n",
    "        # Create the full path for saving the CSV file\n",
    "        csv_filename = f\"{folder_path}/census{year}.csv\"  # Combine folder path and filename\n",
    "\n",
    "        # Save the transformed dataset for the current year to a CSV file\n",
    "        census.to_csv(csv_filename, index=False)  # Save to CSV (without the index)\n",
    "        print(f\"Saved census data for {year} to {csv_filename}\")\n",
    "    else:\n",
    "        print(f\"Dataset for {year} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024 Onwards Growth Rates and Microsimulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           share     value\n",
      "0   social_2024g  0.032989\n",
      "1   social_2025g  0.019193\n",
      "2   social_2026g  0.012367\n",
      "3   social_2027g  0.010859\n",
      "4   social_2028g  0.010948\n",
      "5   social_2029g  0.010987\n",
      "6   social_2030g  0.010941\n",
      "7    child_2024g  0.077339\n",
      "8    child_2025g  0.044419\n",
      "9    child_2026g  0.009034\n",
      "10   child_2027g  0.002045\n",
      "11   child_2028g  0.004717\n",
      "12   child_2029g  0.010578\n",
      "13   child_2030g  0.012262\n",
      "14     cpp_2024g  0.044154\n",
      "15     cpp_2025g  0.026129\n",
      "16     cpp_2026g  0.018968\n",
      "17     cpp_2027g  0.018870\n",
      "18     cpp_2028g  0.020122\n",
      "19     cpp_2029g  0.020020\n",
      "20     cpp_2030g  0.020108\n",
      "21     oas_2024g  0.024188\n",
      "22     oas_2025g  0.018645\n",
      "23     oas_2026g  0.018914\n",
      "24     oas_2027g  0.020359\n",
      "25     oas_2028g  0.019953\n",
      "26     oas_2029g  0.020138\n",
      "27     oas_2030g  0.019741\n",
      "28      ei_2024g  0.033365\n",
      "29      ei_2025g  0.024689\n",
      "30      ei_2026g  0.016714\n",
      "31      ei_2027g  0.017807\n",
      "32      ei_2028g  0.018187\n",
      "33      ei_2029g  0.020394\n",
      "34      ei_2030g  0.021054\n",
      "35    comp_2024g  0.028474\n",
      "36    comp_2025g  0.037466\n",
      "37    comp_2026g  0.037662\n",
      "38    comp_2027g  0.038082\n",
      "39    comp_2028g  0.030099\n",
      "40    comp_2029g  0.028980\n",
      "41    comp_2030g  0.029439\n"
     ]
    }
   ],
   "source": [
    "forecast = pd.read_excel('..\\\\income_growthrates.xlsx')\n",
    "\n",
    "#print all forecast df values\n",
    "print(forecast)\n",
    "\n",
    "\n",
    "# Creating global object that can be referenced later\n",
    "for index, row in forecast.iterrows():\n",
    "    globals()[row['share']] = row['value'] # Assign each row's value to a global variable with the corresponding name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "popproj = pd.read_excel(file_path_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup dictionary for each year's growth rates, considering ECON\n",
    "growth_rate_lookups = {}\n",
    "\n",
    "for year in range(2022, 2031):\n",
    "    growth_rates_year = popproj[['demo', 'agegrp', 'econ', year]]\n",
    "    growth_rate_lookups[year] = {\n",
    "        (row['agegrp'], row['demo'], row['econ']): row[year]\n",
    "        for _, row in growth_rates_year.iterrows()\n",
    "    }\n",
    "\n",
    "def apply_population_growth(row, year):\n",
    "    agegrp_code = row['AGEGRP']\n",
    "    immstat = row['IMMSTAT']\n",
    "    econ = row['econ']  # Ensure ECON is included in calculations\n",
    "    \n",
    "    # Map AGEGRP code to string label\n",
    "    agegrp_label = agegrp_mapping.get(agegrp_code, None)\n",
    "    \n",
    "    if agegrp_label is None:\n",
    "        print(f\"Warning: Unknown AGEGRP code {agegrp_code} in row {row.name}\")\n",
    "        return row  # Leave the row unchanged if AGEGRP is invalid\n",
    "\n",
    "    demo = 'npr' if immstat == 3 else 'nonnpr'\n",
    "    \n",
    "    # Get the growth rate for the year, defaulting to 0% (no change) if missing\n",
    "    growth_rate = growth_rate_lookups[year].get((agegrp_label, demo, econ), 0)\n",
    "    \n",
    "    # Apply the growth rate\n",
    "    row['WEIGHT'] *= (1 + growth_rate)\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved census data for 2024 to ../Microsimulations/census2024.csv\n",
      "Saved census data for 2025 to ../Microsimulations/census2025.csv\n",
      "Saved census data for 2026 to ../Microsimulations/census2026.csv\n",
      "Saved census data for 2027 to ../Microsimulations/census2027.csv\n",
      "Saved census data for 2028 to ../Microsimulations/census2028.csv\n",
      "Saved census data for 2029 to ../Microsimulations/census2029.csv\n",
      "Saved census data for 2030 to ../Microsimulations/census2030.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the years to loop over\n",
    "years = range(2024, 2031)  # Covers 2024 to 2030\n",
    "\n",
    "# Create a dictionary to store census data for each year\n",
    "census= {\"2023\": census2023} #start with 2023 census data\n",
    "weighted_sum_census = {}  # Dictionary to store weighted sum of MRKINC for each year\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    # Initialize the new year's census data by copying the previous year's data\n",
    "    prev_year = str(year - 1)\n",
    "    curr_year = str(year)\n",
    "    census[curr_year] = census[prev_year].copy()\n",
    "\n",
    "    census[curr_year] = census[curr_year].apply(lambda row: apply_population_growth(row, year), axis=1)\n",
    "\n",
    "    year_to_use = year\n",
    "    census[curr_year][\"SHELCO\"] = census[curr_year].apply(adjust_shelco, axis=1)\n",
    "    census[curr_year]['mmr'] = census[curr_year]['mmr']*(1+growth.loc[growth['year'] == year_to_use, 'rent'].values[0])\n",
    "\n",
    "    # Grow transfer income\n",
    "    census[curr_year][\"ei\"] *= (1 + globals()[f\"ei_{curr_year}g\"])\n",
    "    census[curr_year][\"child\"] *= (1 + globals()[f\"child_{curr_year}g\"])\n",
    "    census[curr_year][\"social\"] *= (1 + globals()[f\"social_{curr_year}g\"])\n",
    "    census[curr_year][\"cpp\"] *= (1 + globals()[f\"cpp_{curr_year}g\"])\n",
    "    census[curr_year][\"oas\"] *= (1 + globals()[f\"oas_{curr_year}g\"])\n",
    "\n",
    "    # Compute total transfers for the year\n",
    "    census[curr_year][f\"totaltransfers\"] = (\n",
    "        census[curr_year][\"ei\"] +\n",
    "        census[curr_year][\"child\"] +\n",
    "        census[curr_year][\"social\"] +\n",
    "        census[curr_year][\"cpp\"] +\n",
    "        census[curr_year][\"oas\"]\n",
    "    )\n",
    "\n",
    "    # Grow market income by Canada-wide shares of total income growth for each quintile\n",
    "    #canada_compq1 = 0.7834 * globals()[f\"comp_{curr_year}g\"]\n",
    "    #canada_compq2 = 0.9956 * globals()[f\"comp_{curr_year}g\"]\n",
    "    #canada_compq3 = 1.0034* globals()[f\"comp_{curr_year}g\"]\n",
    "\n",
    "    canada_compq1 = 1 * globals()[f\"comp_{curr_year}g\"]\n",
    "    canada_compq2 = 1 * globals()[f\"comp_{curr_year}g\"]\n",
    "    canada_compq3 = 1* globals()[f\"comp_{curr_year}g\"]\n",
    "\n",
    "\n",
    "\n",
    "    census[curr_year].loc[census[curr_year][\"quintile\"] == 1, \"MRKINC\"] *= (1 + canada_compq1)\n",
    "    census[curr_year].loc[census[curr_year][\"quintile\"] == 2, \"MRKINC\"] *= (1 + canada_compq2)\n",
    "    census[curr_year].loc[census[curr_year][\"quintile\"] == 3, \"MRKINC\"] *= (1 + canada_compq3)\n",
    "    \n",
    "    #create total income variable = transfer income + market income\n",
    "    census[curr_year][\"totalincome\"] = census[curr_year][\"MRKINC\"] + census[curr_year][\"totaltransfers\"]\n",
    "\n",
    "    # Create the full path for saving the CSV file\n",
    "    csv_filename = f\"{folder_path}/census{curr_year}.csv\"  # Combine folder path and filename\n",
    "\n",
    "    # Save the transformed dataset for the current year to a CSV file\n",
    "    census[curr_year].to_csv(csv_filename, index=False)  # Save to CSV (without the index)\n",
    "    print(f\"Saved census data for {curr_year} to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2023\n",
      "   IMMSTAT  AGEGRP      WEIGHT\n",
      "0      1.0    11.0  100.534264\n",
      "Year: 2024\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  98.114029\n",
      "Year: 2025\n",
      "   IMMSTAT  AGEGRP  WEIGHT\n",
      "0      1.0    11.0  98.377\n",
      "Year: 2026\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  97.838664\n",
      "Year: 2027\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  96.929779\n",
      "Year: 2028\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  95.538846\n",
      "Year: 2029\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  93.814007\n",
      "Year: 2030\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  92.438128\n",
      "[np.float64(100.53426364451096), np.float64(98.11402910371264), np.float64(98.37699986746418), np.float64(97.83866366116509), np.float64(96.92977895273891), np.float64(95.53884635781219), np.float64(93.81400667795971), np.float64(92.43812812091856)]\n",
      "[np.float64(-2.407372823017101), np.float64(0.2680256494956119), np.float64(-0.5472175478255608), np.float64(-0.9289627172074034), np.float64(-1.4349899586637003), np.float64(-1.8053804767461896), np.float64(-1.4666024890762832)]\n"
     ]
    }
   ],
   "source": [
    "#check weights were applied properly for first record\n",
    "\n",
    "\n",
    "#print the variables IMMSTAT, AGEGRP, WEIGHT for the first each record in each censusdf then calculate the percent change in the printed WEIGHT value\n",
    "for year, df in census.items():\n",
    "    print(f\"Year: {year}\")\n",
    "    print(df[['IMMSTAT', 'AGEGRP', 'WEIGHT']].head(1))\n",
    "\n",
    "#create an array out of each printed WEIGHT value from the previous loop\n",
    "weights = [df['WEIGHT'].values[0] for df in census.values()]\n",
    "\n",
    "\n",
    "#print weights array\n",
    "print(weights)\n",
    "\n",
    "#calculate the percent change in the values in the weights array\n",
    "percent_change = [(weights[i] - weights[i - 1]) / weights[i - 1] * 100 for i in range(1, len(weights))]\n",
    "print(percent_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create trace file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created transposed summary Excel file with years as columns at ../Microsimulations/census_trace.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the years you want to include\n",
    "years = range(2021, 2031)\n",
    "\n",
    "# List to hold second rows\n",
    "second_rows = []\n",
    "\n",
    "for year in years:\n",
    "    file_path = f\"../Microsimulations/census{year}.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Read the full CSV and select the second row (index 1)\n",
    "        second_row = pd.read_csv(file_path).iloc[[0]].copy()\n",
    "        \n",
    "        # Add a 'year' column\n",
    "        second_row['year'] = year\n",
    "        \n",
    "        # Append to the list\n",
    "        second_rows.append(second_row)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {file_path}\")\n",
    "        continue\n",
    "    except IndexError:\n",
    "        print(f\"File {file_path} does not have a second row.\")\n",
    "        continue\n",
    "\n",
    "# Combine all second rows into one DataFrame\n",
    "summary_df = pd.concat(second_rows, ignore_index=True)\n",
    "\n",
    "# Define the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    'year', 'HH_ID', 'PP_ID', 'SHELCO', 'TENUR', 'PRESMORTG', 'AGEGRP' 'quintile', \n",
    "    'totalincome', 'totaltransfers', 'social', 'cpp', \n",
    "    'ei', 'oas', 'child', 'MRKINC', 'GTRFS'\n",
    "]\n",
    "\n",
    "# Keep only the desired columns (ignore missing ones)\n",
    "summary_df = summary_df[[col for col in columns_to_keep if col in summary_df.columns]]\n",
    "\n",
    "# Set 'year' as the index\n",
    "summary_df.set_index('year', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "summary_transposed = summary_df.transpose()\n",
    "\n",
    "# Save the transposed DataFrame to Excel\n",
    "output_path = \"../Microsimulations/census_trace.xlsx\"\n",
    "summary_transposed.to_excel(output_path)\n",
    "\n",
    "print(f\"Created transposed summary Excel file with years as columns at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved household-level simulation for 2021 -> ../Microsimulations/household/census2021_household.csv\n",
      "Saved household-level simulation for 2022 -> ../Microsimulations/household/census2022_household.csv\n",
      "Saved household-level simulation for 2023 -> ../Microsimulations/household/census2023_household.csv\n",
      "Saved household-level simulation for 2024 -> ../Microsimulations/household/census2024_household.csv\n",
      "Saved household-level simulation for 2025 -> ../Microsimulations/household/census2025_household.csv\n",
      "Saved household-level simulation for 2026 -> ../Microsimulations/household/census2026_household.csv\n",
      "Saved household-level simulation for 2027 -> ../Microsimulations/household/census2027_household.csv\n",
      "Saved household-level simulation for 2028 -> ../Microsimulations/household/census2028_household.csv\n",
      "Saved household-level simulation for 2029 -> ../Microsimulations/household/census2029_household.csv\n",
      "Saved household-level simulation for 2030 -> ../Microsimulations/household/census2030_household.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = \"../Microsimulations\"\n",
    "output_folder = \"../Microsimulations/household\"\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define years for processing\n",
    "years = range(2021, 2031)  # Covers 2023 to 2030\n",
    "\n",
    "# Loop through each year's census simulation file\n",
    "for year in years:\n",
    "    input_file = f\"{input_folder}/census{year}.csv\"\n",
    "    output_file = f\"{output_folder}/census{year}_household.csv\"\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Skipping {year}: File not found -> {input_file}\")\n",
    "        continue\n",
    "\n",
    "    # Load individual-level census data\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Compute average WEIGHT for adults (AGEGRP > 2)\n",
    "    adult_weights = df[df[\"AGEGRP\"] > 2].groupby(\"HH_ID\")[\"WEIGHT\"].mean().reset_index()\n",
    "    adult_weights.rename(columns={\"WEIGHT\": \"avg_adult_weight\"}, inplace=True)\n",
    "\n",
    "    # Group by HH_ID and aggregate\n",
    "    household_df = df.groupby(\"HH_ID\").agg({\n",
    "        \"BEDRM\": \"first\",\n",
    "        \"HCORENEED_IND\": \"first\",\n",
    "        \"REPAIR\": \"first\",\n",
    "        \"NOS\": \"first\",\n",
    "        \"PRESMORTG\": \"first\",\n",
    "        \"SHELCO\": \"first\",\n",
    "        \"TENUR\": \"first\",\n",
    "        \"SUBSIDY\": \"first\",\n",
    "        \"quintile\": \"first\",\n",
    "        \"totalincome\": \"sum\",\n",
    "        \"MRKINC\": \"sum\",\n",
    "        \"TOTINC_AT\": \"sum\",\n",
    "        \"totaltransfers\": \"sum\",\n",
    "        \"mmr\":\"first\",\n",
    "        \"student_household\": \"first\",\n",
    "        \"non_family_household\": \"first\",\n",
    "        \"chn\":\"first\",\n",
    "         \"dchn\":\"first\",\n",
    "        \"bedsuit\":\"first\",\n",
    "        \"stir\" : \"first\"\n",
    "    }).reset_index()\n",
    "\n",
    "   # Merge average adult weight into the household-level dataframe\n",
    "    household_df = household_df.merge(adult_weights, on=\"HH_ID\", how=\"left\")\n",
    "\n",
    "   # Rename the merged column to WEIGHT\n",
    "    household_df.rename(columns={\"avg_adult_weight\": \"WEIGHT\"}, inplace=True)\n",
    "\n",
    "    # Save the transformed household-level data\n",
    "    household_df.to_csv(output_file, index=False)\n",
    "\n",
    "    ###To do: gross up weights to align with FAO household projection###\n",
    "    \n",
    "    print(f\"Saved household-level simulation for {year} -> {output_file}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created transposed summary Excel file with years as columns at ../Microsimulations/household/census_trace_hh.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the years you want to include\n",
    "years = range(2021, 2031)\n",
    "\n",
    "# List to hold second rows\n",
    "second_rows = []\n",
    "\n",
    "for year in years:\n",
    "    file_path = f\"../Microsimulations/household/census{year}_household.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Read the full CSV and select the second row (index 1)\n",
    "        second_row = pd.read_csv(file_path).iloc[[0]].copy()\n",
    "        \n",
    "        # Add a 'year' column\n",
    "        second_row['year'] = year\n",
    "        \n",
    "        # Append to the list\n",
    "        second_rows.append(second_row)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {file_path}\")\n",
    "        continue\n",
    "    except IndexError:\n",
    "        print(f\"File {file_path} does not have a second row.\")\n",
    "        continue\n",
    "\n",
    "# Combine all second rows into one DataFrame\n",
    "summary_df = pd.concat(second_rows, ignore_index=True)\n",
    "\n",
    "# Define the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    'year', 'HH_ID','SHELCO', 'NOS', 'REPAIR', 'BEDRM', 'TENUR', 'PRESMORTG', 'AGEGRP' 'quintile', \n",
    "    'totalincome', 'totaltransfers', 'MRKINC', 'GTRFS'\n",
    "]\n",
    "\n",
    "# Keep only the desired columns (ignore missing ones)\n",
    "summary_df = summary_df[[col for col in columns_to_keep if col in summary_df.columns]]\n",
    "\n",
    "# Set 'year' as the index\n",
    "summary_df.set_index('year', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "summary_transposed = summary_df.transpose()\n",
    "\n",
    "# Save the transposed DataFrame to Excel\n",
    "output_path = \"../Microsimulations/household/census_trace_hh.xlsx\"\n",
    "summary_transposed.to_excel(output_path)\n",
    "\n",
    "print(f\"Created transposed summary Excel file with years as columns at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Year-over-Year Per-Household MRKINC Growth by Quintile ---\n",
      "\n",
      "Quintile 1:\n",
      "Year 2022 | Avg HH MRKINC YoY Growth: 1.07%\n",
      "Year 2023 | Avg HH MRKINC YoY Growth: 6.12%\n",
      "Year 2024 | Avg HH MRKINC YoY Growth: 3.10%\n",
      "Year 2025 | Avg HH MRKINC YoY Growth: 3.15%\n",
      "Year 2026 | Avg HH MRKINC YoY Growth: 3.16%\n",
      "Year 2027 | Avg HH MRKINC YoY Growth: 3.23%\n",
      "Year 2028 | Avg HH MRKINC YoY Growth: 2.62%\n",
      "Year 2029 | Avg HH MRKINC YoY Growth: 2.56%\n",
      "Year 2030 | Avg HH MRKINC YoY Growth: 2.64%\n",
      "\n",
      "Quintile 2:\n",
      "Year 2022 | Avg HH MRKINC YoY Growth: 4.32%\n",
      "Year 2023 | Avg HH MRKINC YoY Growth: 2.82%\n",
      "Year 2024 | Avg HH MRKINC YoY Growth: 2.72%\n",
      "Year 2025 | Avg HH MRKINC YoY Growth: 3.50%\n",
      "Year 2026 | Avg HH MRKINC YoY Growth: 3.39%\n",
      "Year 2027 | Avg HH MRKINC YoY Growth: 3.43%\n",
      "Year 2028 | Avg HH MRKINC YoY Growth: 2.76%\n",
      "Year 2029 | Avg HH MRKINC YoY Growth: 2.61%\n",
      "Year 2030 | Avg HH MRKINC YoY Growth: 2.66%\n",
      "\n",
      "Quintile 3:\n",
      "Year 2022 | Avg HH MRKINC YoY Growth: 7.06%\n",
      "Year 2023 | Avg HH MRKINC YoY Growth: 2.23%\n",
      "Year 2024 | Avg HH MRKINC YoY Growth: 2.71%\n",
      "Year 2025 | Avg HH MRKINC YoY Growth: 3.67%\n",
      "Year 2026 | Avg HH MRKINC YoY Growth: 3.61%\n",
      "Year 2027 | Avg HH MRKINC YoY Growth: 3.65%\n",
      "Year 2028 | Avg HH MRKINC YoY Growth: 2.89%\n",
      "Year 2029 | Avg HH MRKINC YoY Growth: 2.75%\n",
      "Year 2030 | Avg HH MRKINC YoY Growth: 2.80%\n",
      "\n",
      "--- Year-over-Year Per-Household Total Transfers Growth by Quintile ---\n",
      "\n",
      "Quintile 1:\n",
      "Year 2022 | Avg HH Transfers YoY Growth: -0.74%\n",
      "Year 2023 | Avg HH Transfers YoY Growth: -1.91%\n",
      "Year 2024 | Avg HH Transfers YoY Growth: 2.30%\n",
      "Year 2025 | Avg HH Transfers YoY Growth: 3.37%\n",
      "Year 2026 | Avg HH Transfers YoY Growth: 2.75%\n",
      "Year 2027 | Avg HH Transfers YoY Growth: 2.69%\n",
      "Year 2028 | Avg HH Transfers YoY Growth: 2.06%\n",
      "Year 2029 | Avg HH Transfers YoY Growth: 2.09%\n",
      "Year 2030 | Avg HH Transfers YoY Growth: 2.05%\n",
      "\n",
      "Quintile 2:\n",
      "Year 2022 | Avg HH Transfers YoY Growth: -2.97%\n",
      "Year 2023 | Avg HH Transfers YoY Growth: 0.51%\n",
      "Year 2024 | Avg HH Transfers YoY Growth: 4.15%\n",
      "Year 2025 | Avg HH Transfers YoY Growth: 2.85%\n",
      "Year 2026 | Avg HH Transfers YoY Growth: 2.16%\n",
      "Year 2027 | Avg HH Transfers YoY Growth: 2.09%\n",
      "Year 2028 | Avg HH Transfers YoY Growth: 1.97%\n",
      "Year 2029 | Avg HH Transfers YoY Growth: 2.12%\n",
      "Year 2030 | Avg HH Transfers YoY Growth: 2.11%\n",
      "\n",
      "Quintile 3:\n",
      "Year 2022 | Avg HH Transfers YoY Growth: -8.30%\n",
      "Year 2023 | Avg HH Transfers YoY Growth: 4.36%\n",
      "Year 2024 | Avg HH Transfers YoY Growth: 4.40%\n",
      "Year 2025 | Avg HH Transfers YoY Growth: 2.76%\n",
      "Year 2026 | Avg HH Transfers YoY Growth: 2.10%\n",
      "Year 2027 | Avg HH Transfers YoY Growth: 2.02%\n",
      "Year 2028 | Avg HH Transfers YoY Growth: 1.97%\n",
      "Year 2029 | Avg HH Transfers YoY Growth: 2.14%\n",
      "Year 2030 | Avg HH Transfers YoY Growth: 2.15%\n",
      "\n",
      "--- Year-over-Year Per-Household Total Income Growth by Quintile ---\n",
      "\n",
      "Quintile 1:\n",
      "Year 2022 | Avg HH Total Income YoY Growth: -0.12%\n",
      "Year 2023 | Avg HH Total Income YoY Growth: 0.90%\n",
      "Year 2024 | Avg HH Total Income YoY Growth: 2.59%\n",
      "Year 2025 | Avg HH Total Income YoY Growth: 3.29%\n",
      "Year 2026 | Avg HH Total Income YoY Growth: 2.90%\n",
      "Year 2027 | Avg HH Total Income YoY Growth: 2.89%\n",
      "Year 2028 | Avg HH Total Income YoY Growth: 2.27%\n",
      "Year 2029 | Avg HH Total Income YoY Growth: 2.26%\n",
      "Year 2030 | Avg HH Total Income YoY Growth: 2.27%\n",
      "\n",
      "Quintile 2:\n",
      "Year 2022 | Avg HH Total Income YoY Growth: 1.54%\n",
      "Year 2023 | Avg HH Total Income YoY Growth: 1.97%\n",
      "Year 2024 | Avg HH Total Income YoY Growth: 3.24%\n",
      "Year 2025 | Avg HH Total Income YoY Growth: 3.26%\n",
      "Year 2026 | Avg HH Total Income YoY Growth: 2.95%\n",
      "Year 2027 | Avg HH Total Income YoY Growth: 2.95%\n",
      "Year 2028 | Avg HH Total Income YoY Growth: 2.48%\n",
      "Year 2029 | Avg HH Total Income YoY Growth: 2.43%\n",
      "Year 2030 | Avg HH Total Income YoY Growth: 2.47%\n",
      "\n",
      "Quintile 3:\n",
      "Year 2022 | Avg HH Total Income YoY Growth: 3.30%\n",
      "Year 2023 | Avg HH Total Income YoY Growth: 2.69%\n",
      "Year 2024 | Avg HH Total Income YoY Growth: 3.09%\n",
      "Year 2025 | Avg HH Total Income YoY Growth: 3.47%\n",
      "Year 2026 | Avg HH Total Income YoY Growth: 3.27%\n",
      "Year 2027 | Avg HH Total Income YoY Growth: 3.29%\n",
      "Year 2028 | Avg HH Total Income YoY Growth: 2.69%\n",
      "Year 2029 | Avg HH Total Income YoY Growth: 2.62%\n",
      "Year 2030 | Avg HH Total Income YoY Growth: 2.66%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the years and quintiles\n",
    "years = range(2021, 2031)\n",
    "quintiles = [1, 2, 3]\n",
    "\n",
    "# Dictionaries to store weighted sums and weighted counts by year and quintile\n",
    "weighted_HH_MRKINC = {year: {} for year in years}\n",
    "weighted_HH_transfers = {year: {} for year in years}\n",
    "weighted_HH_totalincome = {year: {} for year in years}  # NEW for totalincome\n",
    "weighted_HH_counts = {year: {} for year in years}  # To store sum of weights per quintile\n",
    "\n",
    "# Loop through each year and calculate weighted sums & counts by quintile\n",
    "for year in years:\n",
    "    file_path = f\"../Microsimulations/household/census{year}_household.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Ensure household-level aggregation by taking the first value per HH_ID\n",
    "        df_household = df.groupby(\"HH_ID\").agg(\n",
    "            {\n",
    "                \"MRKINC\": \"first\",\n",
    "                \"totaltransfers\": \"first\",\n",
    "                \"totalincome\": \"first\",  # NEW: Add totalincome\n",
    "                \"WEIGHT\": \"first\",\n",
    "                \"quintile\": \"first\"\n",
    "            }\n",
    "        ).reset_index()\n",
    "\n",
    "        for q in quintiles:\n",
    "            df_q = df_household[df_household[\"quintile\"] == q]\n",
    "            \n",
    "            # Calculate weighted sums\n",
    "            weighted_HH_MRKINC[year][q] = (df_q[\"MRKINC\"] * df_q[\"WEIGHT\"]).sum()\n",
    "            weighted_HH_transfers[year][q] = (df_q[\"totaltransfers\"] * df_q[\"WEIGHT\"]).sum()\n",
    "            weighted_HH_totalincome[year][q] = (df_q[\"totalincome\"] * df_q[\"WEIGHT\"]).sum()  # NEW: Total income\n",
    "            \n",
    "            # Calculate total weight (sum of weights) per quintile\n",
    "            weighted_HH_counts[year][q] = df_q[\"WEIGHT\"].sum()\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {file_path}\")\n",
    "        continue\n",
    "\n",
    "# Compute per-household weighted averages\n",
    "avg_HH_MRKINC = {\n",
    "    year: {q: (weighted_HH_MRKINC[year][q] / weighted_HH_counts[year][q]) if weighted_HH_counts[year][q] != 0 else None for q in quintiles}\n",
    "    for year in years\n",
    "}\n",
    "avg_HH_transfers = {\n",
    "    year: {q: (weighted_HH_transfers[year][q] / weighted_HH_counts[year][q]) if weighted_HH_counts[year][q] != 0 else None for q in quintiles}\n",
    "    for year in years\n",
    "}\n",
    "avg_HH_totalincome = {  # NEW: Compute avg for total income\n",
    "    year: {q: (weighted_HH_totalincome[year][q] / weighted_HH_counts[year][q]) if weighted_HH_counts[year][q] != 0 else None for q in quintiles}\n",
    "    for year in years\n",
    "}\n",
    "\n",
    "# Print Year-over-Year Growth for Household Market Income (MRKINC)\n",
    "print(\"\\n--- Year-over-Year Per-Household MRKINC Growth by Quintile ---\")\n",
    "for q in quintiles:\n",
    "    print(f\"\\nQuintile {q}:\")\n",
    "    for year in range(2022, 2031):  # Start from 2023 since we compare against the previous year\n",
    "        prev = avg_HH_MRKINC.get(year - 1, {}).get(q)\n",
    "        curr = avg_HH_MRKINC.get(year, {}).get(q)\n",
    "        growth = ((curr - prev) / prev) * 100 if prev is not None and prev != 0 else None\n",
    "        print(f\"Year {year} | Avg HH MRKINC YoY Growth: {growth:.2f}%\" if growth is not None else f\"Year {year} | Avg HH MRKINC YoY Growth: N/A\")\n",
    "\n",
    "# Print Year-over-Year Growth for Household Total Transfers\n",
    "print(\"\\n--- Year-over-Year Per-Household Total Transfers Growth by Quintile ---\")\n",
    "for q in quintiles:\n",
    "    print(f\"\\nQuintile {q}:\")\n",
    "    for year in range(2022, 2031):\n",
    "        prev = avg_HH_transfers.get(year - 1, {}).get(q)\n",
    "        curr = avg_HH_transfers.get(year, {}).get(q)\n",
    "        growth = ((curr - prev) / prev) * 100 if prev is not None and prev != 0 else None\n",
    "        print(f\"Year {year} | Avg HH Transfers YoY Growth: {growth:.2f}%\" if growth is not None else f\"Year {year} | Avg HH Transfers YoY Growth: N/A\")\n",
    "\n",
    "# Print Year-over-Year Growth for Household Total Income\n",
    "print(\"\\n--- Year-over-Year Per-Household Total Income Growth by Quintile ---\")\n",
    "for q in quintiles:\n",
    "    print(f\"\\nQuintile {q}:\")\n",
    "    for year in range(2022, 2031):\n",
    "        prev = avg_HH_totalincome.get(year - 1, {}).get(q)\n",
    "        curr = avg_HH_totalincome.get(year, {}).get(q)\n",
    "        growth = ((curr - prev) / prev) * 100 if prev is not None and prev != 0 else None\n",
    "        print(f\"Year {year} | Avg HH Total Income YoY Growth: {growth:.2f}%\" if growth is not None else f\"Year {year} | Avg HH Total Income YoY Growth: N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Weighted Average Household Benefit Values for Quintile 1 ---\n",
      "\n",
      "Year 2023:\n",
      "  Social Benefit: 4,971.47\n",
      "  Cpp Benefit: 4,794.62\n",
      "  Ei Benefit: 621.95\n",
      "  Oas Benefit: 5,997.02\n",
      "  Child Benefit: 890.53\n",
      "  Totaltransfers Benefit: 17,275.59\n",
      "\n",
      "Year 2024:\n",
      "  Social Benefit: 5,074.91\n",
      "  Cpp Benefit: 4,947.28\n",
      "  Ei Benefit: 635.12\n",
      "  Oas Benefit: 6,069.65\n",
      "  Child Benefit: 948.08\n",
      "  Totaltransfers Benefit: 17,675.04\n",
      "\n",
      "Year 2025:\n",
      "  Social Benefit: 5,229.49\n",
      "  Cpp Benefit: 5,132.67\n",
      "  Ei Benefit: 658.00\n",
      "  Oas Benefit: 6,251.17\n",
      "  Child Benefit: 1,001.14\n",
      "  Totaltransfers Benefit: 18,272.47\n"
     ]
    }
   ],
   "source": [
    "# Define the years and benefits of interest\n",
    "years = [2023, 2024, 2025]\n",
    "benefits = [\"social\", \"cpp\", \"ei\", \"oas\", \"child\", \"totaltransfers\"]\n",
    "\n",
    "# Dictionary to store weighted sums and counts per year\n",
    "weighted_sums = {year: {b: 0 for b in benefits} for year in years}\n",
    "total_weights = {year: 0 for year in years}\n",
    "\n",
    "# Process each year's data\n",
    "for year in years:\n",
    "    file_path = f\"../Microsimulations/census{year}.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Group by household (HH_ID) and aggregate:\n",
    "        df_household = df.groupby(\"HH_ID\").agg(\n",
    "            {b: \"sum\" for b in benefits} | {\"WEIGHT\": \"first\", \"quintile\": \"first\"}  # Sum benefits, keep first weight & quintile\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Filter for Quintile 1\n",
    "        df_q1 = df_household[df_household[\"quintile\"] == 1]\n",
    "        \n",
    "        # Compute weighted sums for each benefit\n",
    "        for b in benefits:\n",
    "            weighted_sums[year][b] = (df_q1[b] * df_q1[\"WEIGHT\"]).sum()\n",
    "        \n",
    "        # Compute total weight for Quintile 1\n",
    "        total_weights[year] = df_q1[\"WEIGHT\"].sum()\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {file_path}\")\n",
    "        continue\n",
    "\n",
    "# Compute weighted averages\n",
    "weighted_averages = {\n",
    "    year: {b: (weighted_sums[year][b] / total_weights[year]) if total_weights[year] > 0 else None for b in benefits}\n",
    "    for year in years\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\n--- Weighted Average Household Benefit Values for Quintile 1 ---\")\n",
    "for year in years:\n",
    "    print(f\"\\nYear {year}:\")\n",
    "    for b in benefits:\n",
    "        value = weighted_averages[year][b]\n",
    "        print(f\"  {b.capitalize()} Benefit: {value:,.2f}\" if value is not None else f\"  {b.capitalize()} Benefit: N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
