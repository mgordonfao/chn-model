{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Income Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_dir = os.getenv(\"DATA_PATH\")\n",
    "\n",
    "file_path = os.path.join(data_dir, \"Statistics Canada\", \"incomes_quintile_hh.xlsx\")\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_comp_all\"] = np.log(df[\"comp_all\"])\n",
    "# Define independent (compx) and dependent (comp) variables\n",
    "compx = df[[\"log_comp_all\"]]  # Log of total income as independent variable\n",
    "\n",
    "# Add a constant term (intercept)\n",
    "compx = sm.add_constant(compx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quintile 1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q1   R-squared:                       0.914\n",
      "Model:                            OLS   Adj. R-squared:                  0.910\n",
      "Method:                 Least Squares   F-statistic:                     254.2\n",
      "Date:                Fri, 10 Oct 2025   Prob (F-statistic):           2.85e-14\n",
      "Time:                        09:28:56   Log-Likelihood:                 41.701\n",
      "No. Observations:                  26   AIC:                            -79.40\n",
      "Df Residuals:                      24   BIC:                            -76.89\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.5008      0.540      0.927      0.363      -0.615       1.616\n",
      "log_comp_all     0.7797      0.049     15.944      0.000       0.679       0.881\n",
      "==============================================================================\n",
      "Omnibus:                        5.847   Durbin-Watson:                   1.740\n",
      "Prob(Omnibus):                  0.054   Jarque-Bera (JB):                3.937\n",
      "Skew:                          -0.722   Prob(JB):                        0.140\n",
      "Kurtosis:                       4.245   Cond. No.                         606.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Quintile 2\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q2   R-squared:                       0.971\n",
      "Model:                            OLS   Adj. R-squared:                  0.969\n",
      "Method:                 Least Squares   F-statistic:                     791.6\n",
      "Date:                Fri, 10 Oct 2025   Prob (F-statistic):           6.89e-20\n",
      "Time:                        09:28:56   Log-Likelihood:                 50.214\n",
      "No. Observations:                  26   AIC:                            -96.43\n",
      "Df Residuals:                      24   BIC:                            -93.91\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.7190      0.390     -1.846      0.077      -1.523       0.085\n",
      "log_comp_all     0.9917      0.035     28.135      0.000       0.919       1.064\n",
      "==============================================================================\n",
      "Omnibus:                        4.231   Durbin-Watson:                   1.017\n",
      "Prob(Omnibus):                  0.121   Jarque-Bera (JB):                2.484\n",
      "Skew:                           0.559   Prob(JB):                        0.289\n",
      "Kurtosis:                       4.022   Cond. No.                         606.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Quintile 3\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q3   R-squared:                       0.987\n",
      "Model:                            OLS   Adj. R-squared:                  0.987\n",
      "Method:                 Least Squares   F-statistic:                     1864.\n",
      "Date:                Fri, 10 Oct 2025   Prob (F-statistic):           2.88e-24\n",
      "Time:                        09:28:56   Log-Likelihood:                 61.098\n",
      "No. Observations:                  26   AIC:                            -118.2\n",
      "Df Residuals:                      24   BIC:                            -115.7\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.2169      0.256     -0.846      0.406      -0.746       0.312\n",
      "log_comp_all     1.0014      0.023     43.180      0.000       0.954       1.049\n",
      "==============================================================================\n",
      "Omnibus:                        0.680   Durbin-Watson:                   1.318\n",
      "Prob(Omnibus):                  0.712   Jarque-Bera (JB):                0.253\n",
      "Skew:                           0.241   Prob(JB):                        0.881\n",
      "Kurtosis:                       3.022   Cond. No.                         606.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Quintile 4\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q4   R-squared:                       0.994\n",
      "Model:                            OLS   Adj. R-squared:                  0.994\n",
      "Method:                 Least Squares   F-statistic:                     4296.\n",
      "Date:                Fri, 10 Oct 2025   Prob (F-statistic):           1.40e-28\n",
      "Time:                        09:28:56   Log-Likelihood:                 71.245\n",
      "No. Observations:                  26   AIC:                            -138.5\n",
      "Df Residuals:                      24   BIC:                            -136.0\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.0432      0.173     -0.249      0.805      -0.401       0.315\n",
      "log_comp_all     1.0289      0.016     65.545      0.000       0.996       1.061\n",
      "==============================================================================\n",
      "Omnibus:                        6.066   Durbin-Watson:                   0.757\n",
      "Prob(Omnibus):                  0.048   Jarque-Bera (JB):                4.103\n",
      "Skew:                          -0.866   Prob(JB):                        0.129\n",
      "Kurtosis:                       3.886   Cond. No.                         606.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Quintile 5\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_comp_q5   R-squared:                       0.994\n",
      "Model:                            OLS   Adj. R-squared:                  0.994\n",
      "Method:                 Least Squares   F-statistic:                     4182.\n",
      "Date:                Fri, 10 Oct 2025   Prob (F-statistic):           1.92e-28\n",
      "Time:                        09:28:56   Log-Likelihood:                 71.670\n",
      "No. Observations:                  26   AIC:                            -139.3\n",
      "Df Residuals:                      24   BIC:                            -136.8\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            0.8361      0.171      4.899      0.000       0.484       1.188\n",
      "log_comp_all     0.9987      0.015     64.671      0.000       0.967       1.031\n",
      "==============================================================================\n",
      "Omnibus:                        0.316   Durbin-Watson:                   0.736\n",
      "Prob(Omnibus):                  0.854   Jarque-Bera (JB):                0.464\n",
      "Skew:                          -0.204   Prob(JB):                        0.793\n",
      "Kurtosis:                       2.488   Cond. No.                         606.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):  \n",
    "    quantile_col = f\"comp_q{i}\"\n",
    "    log_quantile_col = f\"log_comp_q{i}\"\n",
    "    \n",
    "    if quantile_col not in df.columns:\n",
    "        print(f\"Column {quantile_col} not found in DataFrame.\")\n",
    "        continue  # Skip if the column is missing\n",
    "\n",
    "    # Handle zero or negative values before log transformation\n",
    "    if (df[quantile_col] <= 0).any():\n",
    "        print(f\"Skipping {quantile_col} due to zero/negative values.\")\n",
    "        continue\n",
    "\n",
    "    # Compute log for the current quantile\n",
    "    df[log_quantile_col] = np.log(df[quantile_col])\n",
    "\n",
    "    # Define dependent variable (compy)\n",
    "    compy = df[log_quantile_col]\n",
    "    \n",
    "    # Run the regression\n",
    "    model = sm.OLS(compy, compx).fit()\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Quintile {i}\")\n",
    "    print(model.summary())\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Growth Rates for 2022 & 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate growth rates \n",
    "\n",
    "for i in range(1, 6):\n",
    "    df[f\"compq{i}_g\"] = df[f\"comp_q{i}\"].pct_change()\n",
    "    df[f\"tranrq{i}_g\"] = df[f\"tranr_q{i}\"].pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canada_compq1_2022: 0.012403379471508158\n",
      "canada_compq1_2023: 0.05779474431818188\n",
      "canada_compq1_2024: 0.012589173310952662\n",
      "canada_compq2_2022: 0.039472560020505254\n",
      "canada_compq2_2023: 0.028740513438724413\n",
      "canada_compq2_2024: 0.0682859273463301\n",
      "canada_compq3_2022: 0.06814698983580914\n",
      "canada_compq3_2023: 0.023233003454939283\n",
      "canada_compq3_2024: 0.06461120251806274\n",
      "canada_compq4_2022: 0.07878008173149698\n",
      "canada_compq4_2023: 0.023342686776569588\n",
      "canada_compq4_2024: 0.046177443402855234\n",
      "canada_compq5_2022: 0.07499350214843847\n",
      "canada_compq5_2023: 0.04678224188487068\n",
      "canada_compq5_2024: 0.0237315956045685\n",
      "canada_tranrq1_2022: -0.0039343480507093576\n",
      "canada_tranrq1_2023: -0.006742738589211594\n",
      "canada_tranrq1_2024: 0.03779875477003425\n",
      "canada_tranrq2_2022: -0.02424912235079968\n",
      "canada_tranrq2_2023: 0.004563928309680776\n",
      "canada_tranrq2_2024: 0.03405737025368927\n",
      "canada_tranrq3_2022: -0.07645217869793997\n",
      "canada_tranrq3_2023: 0.04148357786549495\n",
      "canada_tranrq3_2024: 0.036434496567505636\n",
      "canada_tranrq4_2022: -0.09942419799005753\n",
      "canada_tranrq4_2023: -0.012469719232754861\n",
      "canada_tranrq4_2024: 0.04869907910081639\n",
      "canada_tranrq5_2022: -0.11292128324904449\n",
      "canada_tranrq5_2023: 0.06889198363652183\n",
      "canada_tranrq5_2024: 0.09722731159154763\n"
     ]
    }
   ],
   "source": [
    "#store growth rates for 2022 and 2023 in a dictionary\n",
    "\n",
    "vars = ['compq1', 'compq2', 'compq3', 'compq4', 'compq5', 'tranrq1', 'tranrq2', 'tranrq3', 'tranrq4', 'tranrq5']\n",
    "growth_rates = {}  # Dictionary to store variable names and values\n",
    "\n",
    "for var in vars:\n",
    "    # Dynamically fetch values for 2022 and 2023 and assign them to keys in the dictionary\n",
    "    growth_rates[f'canada_{var}_2022'] = df.loc[df['year'] == 2022, f'{var}_g'].values[0]\n",
    "    growth_rates[f'canada_{var}_2023'] = df.loc[df['year'] == 2023, f'{var}_g'].values[0]\n",
    "    growth_rates[f'canada_{var}_2024'] = df.loc[df['year'] == 2024, f'{var}_g'].values[0]\n",
    "\n",
    "# Now print the stored results from the dictionary\n",
    "for key, value in growth_rates.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import 2021 census, filter data\n",
    "\n",
    "\n",
    "file_path_census = os.path.join(data_dir, \"Statistics Canada\", \"Census 2021\", \"Hierarchical\", \"censush.csv\")\n",
    "census2021 = pd.read_csv(file_path_census)\n",
    "census2021 = census2021[census2021[\"PR\"] == 35]\n",
    "\n",
    "# Drop rows where income equals 88888888 (dropping NA values)\n",
    "census2021 = census2021[census2021[\"TOTINC\"] != 88888888]\n",
    "census2021 = census2021[census2021[\"MRKINC\"] != 88888888]\n",
    "census2021 = census2021[census2021[\"GTRFS\"] != 88888888]\n",
    "census2021 = census2021[census2021[\"TOTINC_AT\"] != 88888888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "wt_columns = [f\"WT{i}\" for i in range(1, 17)]\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"ABOID\", \"AGEIMM\", \"BFNMEMB\", \"BUILT\", \"CF_RP\", \"CFSTRUCT\", \"CIP2021\", \"CITIZEN\", \"CITOTH\",\n",
    "    \"CONDO\", \"COW\", \"DIST\", \"DTYPE\", \"EF_RP\", \"EFCOVID_ERB\", \"EFDECILE\", \"EFDIMBM_2018\", \"EMPIN\", \n",
    "    \"ETHDER\", \"FCOND\", \"FOL\", \"FPTWK\", \"GENDER\", \"GENSTAT\", \"HDGREE\", \"HLMOSTEN\", \n",
    "    \"HLMOSTFR\", \"HLMOSTNO\", \"HLREGEN\", \"HLREGFR\", \"HLREGNO\", \"HRSWRK\", \"INCTAX\", \"JOBPERM\", \"KOL\", \n",
    "   \"LI_ELIG_OML_U18\", \"LICO_AT\", \"LICO_BT\", \"LOC_ST_RES\", \"LOCSTUD\", \"LOLIMA\", \"LOLIMB\", \n",
    "    \"LOMBM_2018\", \"LSTWRK\", \"LWMOSTEN\", \"LWMOSTFR\", \"LWMOSTNO\", \"LWREGEN\", \"LWREGFR\", \"LWREGNO\", \n",
    "    \"MARSTH\", \"MOB1\", \"MOB5\", \"MODE\"\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "census2021 = census2021.drop(columns=wt_columns)\n",
    "census2021 = census2021.drop(columns=columns_to_drop, errors=\"ignore\")  # 'errors=\"ignore\"' ensures no error if a column is missing\n",
    "\n",
    "\n",
    "#set IMMSTAT = 1 if equal to 8\n",
    "census2021[\"IMMSTAT\"] = census2021[\"IMMSTAT\"].replace(8, 1)\n",
    "\n",
    "#create suitable bedroom variavle\n",
    "\n",
    "\n",
    "# Step 1: Define Household-Level Calculation\n",
    "def household_bedsuit(group):\n",
    "    num_couples = (group['CFSTAT'] == 1).sum() // 2 + (group['CFSTAT'] == 2).sum() // 2 # Couples share a room\n",
    "    num_single_parents = (group['CFSTAT'] == 3).sum()  # Each single parent gets a room\n",
    "    num_children = (group['CFSTAT'].isin([4, 5])).sum()  # Count children\n",
    "    num_non_family = (group['CFSTAT'].isin([7, 8])).sum()  # Each gets their own room\n",
    "    num_living_alone = (group['CFSTAT'] == 6).sum()  # People living alone\n",
    "\n",
    "    # If the household has exactly 1 person and they live alone â†’ Assign bedsuit = 0 (bachelor unit)\n",
    "    if len(group) == 1 and num_living_alone == 1:\n",
    "        return 0  \n",
    "\n",
    "    # Start with bedrooms for couples and single parents\n",
    "    bedrooms_needed = num_couples + num_single_parents\n",
    "\n",
    "    # Assign bedrooms for children: Every 2 children share 1 room\n",
    "    if num_children > 0:\n",
    "        bedrooms_needed += (num_children + 1) // 2  # Round up when odd number of children\n",
    "\n",
    "    # Add rooms for non-family members (CFSTAT = 7, 8)\n",
    "    bedrooms_needed += num_non_family\n",
    "\n",
    "    # If NOS == 1, ensure bedsuit does NOT exceed BEDRM\n",
    "    if 'NOS' in group.columns and group['NOS'].eq(1).any():  # Ensure 'NOS' exists\n",
    "        max_bedrooms = group['BEDRM'].dropna().max()  # Get the max BEDRM in household\n",
    "        if pd.notna(max_bedrooms):  \n",
    "            bedrooms_needed = min(bedrooms_needed, max_bedrooms)  # Ensure it doesn't exceed BEDRM\n",
    "\n",
    "    return bedrooms_needed\n",
    "\n",
    "# Step 2: **Initialize `bedsuit` column with NaN**\n",
    "census2021['bedsuit'] = pd.NA\n",
    "\n",
    "# Step 3: Apply household-level logic\n",
    "census2021['bedsuit'] = census2021.groupby('HH_ID')['bedsuit'].transform(\n",
    "    lambda x: household_bedsuit(census2021.loc[x.index])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create unemployment indicator\n",
    "def assign_econ(row):\n",
    "    if row['AGEGRP'] in [1, 2]:\n",
    "        return 3\n",
    "    elif 2 < row['LFACT'] <= 10 and row['AGEGRP'] >= 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to create the ECON variable in census21\n",
    "census2021['econ'] = census2021.apply(assign_econ, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Build the full path to amr2021.xlsx\n",
    "file_path = os.path.join(data_dir, \"amr2021.xlsx\")\n",
    "\n",
    "\n",
    "#create a median market rent variable for Toronto/not-Toronto, by bedrooms for 2021\n",
    "amr2021 = pd.read_excel(file_path)\n",
    "# Perform a left join to add the MMR column to census2021\n",
    "census2021 = census2021.merge(amr2021, on=['bedsuit', 'CMA'], how='left')\n",
    "\n",
    "census2021['mmr'] = census2021['mmr'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with TOTINC > 88000000: 0\n",
      "Number of records with MRKINC > 88000000: 0\n",
      "Number of records with GTRFS > 88000000: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Correct missing values (children with no income)\n",
    "census2021.loc[census2021[\"TOTINC\"] > 88000000, \"TOTINC\"] = 0\n",
    "census2021.loc[census2021[\"MRKINC\"] > 88000000, \"MRKINC\"] = 0\n",
    "census2021.loc[census2021[\"GTRFS\"] > 88000000, \"GTRFS\"] = 0\n",
    "census2021.loc[census2021[\"TOTINC_AT\"] > 88000000, \"TOTINC_AT\"] = 0\n",
    "\n",
    "#check missing and NA values\n",
    "variables = [\"TOTINC\", \"MRKINC\", \"GTRFS\"]\n",
    "for var in variables:\n",
    "    count = (census2021[var] > 88000000).sum()\n",
    "    print(f\"Number of records with {var} > 88000000: {count}\")\n",
    "\n",
    "census2021[\"totaltransfers\"] = census2021[\"GTRFS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create quintiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HH_ID  TOTINC  quintile\n",
      "0      1   12000         1\n",
      "1      4   34000         4\n",
      "2      4   97000         4\n",
      "3      4       0         4\n",
      "4      4       0         4\n",
      "5      4       0         4\n",
      "6      6    3000         3\n",
      "7      6    8000         3\n",
      "8      6   69000         3\n",
      "9      6       0         3\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a new column for total income\n",
    "census2021[\"totalincome\"] = census2021[\"MRKINC\"] + census2021[\"GTRFS\"]\n",
    "\n",
    "# Step 2: Compute total household income (sum of MRKINC and GTRFS)\n",
    "household_income = census2021.groupby(\"HH_ID\").agg(\n",
    "    totalincome=(\"totalincome\", \"sum\"),  # Sum of the newly created totalincome\n",
    "    weight=(\"WEIGHT\", \"first\")  # Take first weight per household\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Step 3: Compute weighted quintiles\n",
    "def weighted_quantile(values, quantiles, sample_weight):\n",
    "    \"\"\"Calculate weighted quantiles for a given dataset.\"\"\"\n",
    "    sorter = np.argsort(values)\n",
    "    values, sample_weight = values[sorter], sample_weight[sorter]\n",
    "    weighted_cdf = np.cumsum(sample_weight) / np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_cdf, values)\n",
    "\n",
    "# Compute cutoff points for weighted quintiles\n",
    "quantile_cutoffs = weighted_quantile(\n",
    "    household_income[\"totalincome\"].values,\n",
    "    quantiles=[0.2, 0.4, 0.6, 0.8],\n",
    "    sample_weight=household_income[\"weight\"].values\n",
    ")\n",
    "\n",
    "# Step 4: Assign households to weighted quintiles\n",
    "household_income[\"quintile\"] = np.digitize(household_income[\"totalincome\"], bins=quantile_cutoffs, right=True) + 1\n",
    "\n",
    "# Step 5: Merge the quintile info back to the original dataset\n",
    "census2021 = census2021.merge(household_income[[\"HH_ID\", \"quintile\"]], on=\"HH_ID\", how=\"left\")\n",
    "\n",
    "# Step 6: Verify the result\n",
    "print(census2021[[\"HH_ID\", \"TOTINC\", \"quintile\"]].head(10))\n",
    "\n",
    "#subset census2021 for only quintiles 1 and 2\n",
    "census2021 = census2021[census2021[\"quintile\"].isin([1, 2, 3])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 2021 Core Housing Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Aggregate total household income\n",
    "household_income2 = census2021.groupby('HH_ID')['totalincome'].sum().reset_index()\n",
    "\n",
    "# Step 2: Merge back into census2021\n",
    "census2021 = census2021.merge(household_income2, on='HH_ID', suffixes=('', '_hh'))\n",
    "\n",
    "\n",
    "# identify households where every preson in unrelated or living alone\n",
    "household_non_family = census2021.groupby('HH_ID')['CFSTAT'].apply(lambda x: set(x).issubset({6, 7})).reset_index()\n",
    "household_non_family.columns = ['HH_ID', 'non_family_household']\n",
    "household_non_family['non_family_household'] = household_non_family['non_family_household'].astype(int)\n",
    "\n",
    "#merge back into census2021\n",
    "census2021 = census2021.merge(household_non_family, on='HH_ID', how='left')\n",
    "\n",
    "#Identify households where at least one maintainer (HHMAINP == 1) is aged 15-29 and attending school\n",
    "maintainers = census2021[(census2021['HHMAINP'] == 1) & \n",
    "                         (census2021['AGEGRP'].isin([3, 4, 5])) & \n",
    "                         (census2021['ATTSCH'] == 1)]\n",
    "\n",
    "excluded_households = maintainers['HH_ID'].unique()\n",
    "census2021['student_household'] = census2021['HH_ID'].isin(excluded_households).astype(int) # 1 if student, 0 otherwise\n",
    "\n",
    "# Step 3: Define Core Housing Need (CHN)\n",
    "census2021['chn'] = 0  # Default to 0 (not in CHN)\n",
    "\n",
    "# Condition: Housing is unaffordable OR unsuitable OR inadequate\n",
    "housing_issue = (\n",
    "    (census2021['SHELCO'] * 12 / census2021['totalincome_hh'] > 0.30) |  # Unaffordable\n",
    "    (census2021['NOS'] == 0) |  # Unsuitable\n",
    "    (census2021['REPAIR'] == 3)  # Inadequate\n",
    ")\n",
    "\n",
    "# Condition: Alternative market rent is also unaffordable\n",
    "market_unaffordable = (census2021['mmr']) * 12 > 0.30 * census2021['totalincome_hh']\n",
    "\n",
    "# Set Core Housing Need (CHN) variable, excluding non-family households with an eligible maintainer\n",
    "census2021.loc[housing_issue & market_unaffordable & \n",
    "               ~((census2021['student_household'] == 1) & (census2021['non_family_household'] == 1)), \n",
    "               'chn'] = 1\n",
    "\n",
    "\n",
    "# Create STIR (Shelter Cost to Income Ratio)\n",
    "census2021[\"stir\"] = (census2021[\"SHELCO\"] * 12) / census2021[\"totalincome_hh\"]\n",
    "\n",
    "# Create ALTSTIR (Alternative STIR using AMR)\n",
    "census2021[\"altstir\"] = (census2021[\"mmr\"] * 12) / census2021[\"totalincome_hh\"]\n",
    "\n",
    "# Update CHN: Exclude individuals with STIR >= 1\n",
    "census2021.loc[census2021[\"stir\"] >= 1, \"chn\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Define Deep Core Housing Need (DCHN)\n",
    "census2021['dchn'] = 0  # Default to 0\n",
    "\n",
    "deep_housing_issue = (\n",
    "    (census2021['SHELCO'] * 12 / census2021['totalincome_hh'] > 0.50) |  # Deeply unaffordable\n",
    "    (census2021['NOS'] == 0) |  # Unsuitable\n",
    "    (census2021['REPAIR'] == 3)  # Inadequate\n",
    ")\n",
    "\n",
    "deep_market_unaffordable = (census2021['mmr']) * 12 > 0.50 * census2021['totalincome_hh']\n",
    "\n",
    "# Apply DCHN flag with same exclusions\n",
    "census2021.loc[deep_housing_issue & deep_market_unaffordable &\n",
    "               ~((census2021['student_household'] == 1) & (census2021['non_family_household'] == 1)), \n",
    "               'dchn'] = 1\n",
    "\n",
    "# Update DCHN: Exclude individuals with STIR >= 1\n",
    "census2021.loc[census2021[\"stir\"] >= 1, \"dchn\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "census2022 = census2021.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the population projection file\n",
    "file_path_pop = os.path.join(data_dir, \"popproj.xlsx\")\n",
    "popproj = pd.read_excel(file_path_pop)\n",
    "\n",
    "# Filter to 2022 growth rates only\n",
    "growth_rates_2022 = popproj[['demo', 'agegrp', 'econ', 2022]]\n",
    "\n",
    "# Create a lookup dictionary: {(agegrp, demo, econ): growth_rate}\n",
    "growth_rate_lookup = {\n",
    "    (row['agegrp'], row['demo'], row['econ']): row[2022]\n",
    "    for _, row in growth_rates_2022.iterrows()\n",
    "}\n",
    "\n",
    "# Define the AGEGRP mapping from numbers to labels\n",
    "agegrp_mapping = {\n",
    "    1: '0to9',\n",
    "    2: '10to14',\n",
    "    3: '15to19',\n",
    "    4: '20to24',\n",
    "    5: '25to29',\n",
    "    6: '30to34',\n",
    "    7: '35to39',\n",
    "    8: '40to44',\n",
    "    9: '45to49',\n",
    "    10: '50to54',\n",
    "    11: '55to64',\n",
    "    12: '65to74',\n",
    "    13: '75plus',\n",
    "    88: \"total\"\n",
    "}\n",
    "\n",
    "# Function to apply growth rates based on AGEGRP, IMMSTAT, and ECON\n",
    "def apply_growth(row):\n",
    "    agegrp_code = row['AGEGRP']\n",
    "    immstat = row['IMMSTAT']\n",
    "    econ = row['econ']\n",
    "\n",
    "    # Map AGEGRP code to string label\n",
    "    agegrp_label = agegrp_mapping.get(agegrp_code, None)\n",
    "    \n",
    "    if agegrp_label is None:\n",
    "        print(f\"Warning: Unknown AGEGRP code {agegrp_code} in row {row.name}\")\n",
    "        return row  # Skip updating this row\n",
    "\n",
    "    # Determine if the person is NPR or non-NPR based on IMMSTAT\n",
    "    demo = 'npr' if immstat == 3 else 'nonnpr'\n",
    "    \n",
    "    # Lookup the growth rate, defaulting to 1 if not found\n",
    "    growth_rate = growth_rate_lookup.get((agegrp_label, demo, econ), 1)\n",
    "    \n",
    "    # Apply the growth rate\n",
    "    row['WEIGHT'] *= (1 + growth_rate)\n",
    "    return row\n",
    "\n",
    "# Apply the updated growth function to census2022\n",
    "census2022 = census2022.apply(apply_growth, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary statistics:\n",
    "income quintile ranges\n",
    "number of households per quintile\n",
    "number of household in CHN per quintile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             min      max\n",
      "quintile                 \n",
      "1         -38300    44300\n",
      "2          44301    74500\n",
      "3          74501   109900\n",
      "4         110000   162101\n",
      "5         162200  1613152\n",
      "quintile\n",
      "1    1,104,493\n",
      "2    1,104,192\n",
      "3    1,102,284\n",
      "Name: WEIGHT, dtype: object\n",
      "Total households (weighted): 3,310,969\n"
     ]
    }
   ],
   "source": [
    "# Show the min and max household income for each quintile\n",
    "print(household_income.groupby(\"quintile\")[\"totalincome\"].agg([\"min\", \"max\"]))\n",
    "\n",
    "# Step 1: Aggregate weights at the household level\n",
    "household_weights = census2021.groupby(\"HH_ID\")[\"WEIGHT\"].first().reset_index()\n",
    "\n",
    "# Step 2: Merge back the quintile information\n",
    "household_weights = household_weights.merge(\n",
    "    household_income[[\"HH_ID\", \"quintile\"]], on=\"HH_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Step 3: Compute weighted household counts by quintile\n",
    "household_weighted_counts = household_weights.groupby(\"quintile\")[\"WEIGHT\"].sum()\n",
    "\n",
    "# Print results with comma separators\n",
    "print(household_weighted_counts.apply(lambda x: f\"{x:,.0f}\"))\n",
    "\n",
    "# Sum total weights across all households\n",
    "total_weight = household_weighted_counts.sum()\n",
    "print(f\"Total households (weighted): {total_weight:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quintile\n",
      "1    467,645\n",
      "2    166,994\n",
      "3      5,824\n",
      "Name: WEIGHT, dtype: object\n",
      "640463.50217058\n"
     ]
    }
   ],
   "source": [
    "# Keep one row per household in core housing need\n",
    "core_housing_need_households = (\n",
    "    census2021[census2021[\"HCORENEED_IND\"] == 100]\n",
    "    .drop_duplicates(subset=\"HH_ID\")\n",
    ")\n",
    "\n",
    "# Sum of household weights by quintile\n",
    "core_housing_need_weighted = (\n",
    "    core_housing_need_households.groupby(\"quintile\")[\"WEIGHT\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# Format numbers with comma separators\n",
    "print(core_housing_need_weighted.apply(lambda x: f\"{x:,.0f}\"))\n",
    "\n",
    "#print sum of households in core housing need\n",
    "total_core_housing_need = core_housing_need_weighted.sum()\n",
    "print(total_core_housing_need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grow market income for 2022 based on Canada quintile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_mrkinc(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq1_2022'])*0.9982\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq2_2022'])*0.9937\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq3_2022'])*0.9960\n",
    "    elif row['quintile'] == 4:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq4_2022'])\n",
    "    elif row['quintile'] == 5:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq5_2022'])\n",
    "    else:\n",
    "        return row['MRKINC']  # Default case if quintile is missing\n",
    "\n",
    "# Apply function row-wise\n",
    "census2022.loc[:, 'MRKINC'] = census2022.apply(adjust_mrkinc, axis=1).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grow transfer income for 2022 based on Canada quintile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gtrfs(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq1_2022'])*1.0045\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq2_2022'])*1.0097\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq3_2022'])*1.0116\n",
    "    else:\n",
    "        return row['GTRFS']  # Default case if quintile is missing\n",
    "\n",
    "# Apply function row-wise\n",
    "census2022.loc[:, 'GTRFS'] = census2022.apply(adjust_gtrfs, axis=1).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new variable for total income (after growing MRKINC and GTRFS)\n",
    "census2022[\"totalincome\"] = census2022[\"MRKINC\"] + census2022[\"GTRFS\"]\n",
    "census2022[\"totaltransfers\"] = census2022[\"GTRFS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quintile  avg_totalincome\n",
      "0       1.0     18488.901394\n",
      "1       2.0     28881.551514\n",
      "2       3.0     36907.454625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgordon\\AppData\\Local\\Temp\\ipykernel_31512\\2768629471.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: weighted_mean(g[\"totalincome\"], g[\"WEIGHT\"]))\n"
     ]
    }
   ],
   "source": [
    "# Weighted mean function\n",
    "def weighted_mean(x, w):\n",
    "    return np.sum(x * w) / np.sum(w)\n",
    "\n",
    "# Group by quintile and compute weighted average of totalincome\n",
    "avg_income_by_quintile = (\n",
    "    census2022\n",
    "    .groupby(\"quintile\")\n",
    "    .apply(lambda g: weighted_mean(g[\"totalincome\"], g[\"WEIGHT\"]))\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for nicer display\n",
    "avg_income_by_quintile = avg_income_by_quintile.reset_index(name=\"avg_totalincome\")\n",
    "\n",
    "print(avg_income_by_quintile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grow 2022 shelco based on tenur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SHELCO     mmr\n",
      "0   200.0   900.0\n",
      "1   800.0  1700.0\n",
      "2   800.0  1700.0\n",
      "3   800.0  1700.0\n",
      "4   800.0  1700.0\n"
     ]
    }
   ],
   "source": [
    "print(census2022[['SHELCO', 'mmr']].head()) #check values before growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year      rent  mortgage  othercosts\n",
      "0  2022  0.052632  0.078221    0.028594\n",
      "1  2023  0.071429  0.102674    0.033550\n",
      "2  2024  0.053333  0.041514    0.042860\n",
      "3  2025  0.035739  0.035362    0.035998\n",
      "4  2026  0.026306  0.045493    0.034412\n",
      "       SHELCO     mmr\n",
      "0  210.526316   900.0\n",
      "1  822.875193  1700.0\n",
      "2  822.875193  1700.0\n",
      "3  822.875193  1700.0\n",
      "4  822.875193  1700.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_path_growth = os.path.join(data_dir, \"growthrates.xlsx\")\n",
    "growth = pd.read_excel(file_path_growth)\n",
    "\n",
    "print(growth.head())\n",
    "\n",
    "#increase shelco variable by the 2022 rent variable in the growth df, if tenur is 2, increase by the mortgage variable if tenur is 1\n",
    "\n",
    "year_to_use = 2022 \n",
    "\n",
    "def adjust_shelco(row):\n",
    "    rent = growth.loc[growth['year'] == year_to_use, 'rent'].values[0]\n",
    "    mortgage = growth.loc[growth['year'] == year_to_use, 'mortgage'].values[0]\n",
    "    othercosts = growth.loc[growth['year'] == year_to_use, 'othercosts'].values[0]\n",
    "\n",
    "    if row['TENUR'] == 2:  # Renters\n",
    "        return row['SHELCO'] * (1 + rent)\n",
    "    elif row['TENUR'] == 1:\n",
    "        if row['PRESMORTG'] in [1, 8]:  # Mortgage holders\n",
    "            return row['SHELCO'] * (1 + mortgage)\n",
    "        elif row['PRESMORTG'] == 0:  # No mortgage, use othercosts\n",
    "            return row['SHELCO'] * (1 + othercosts)\n",
    "    \n",
    "    # Default case\n",
    "    return row['SHELCO'] * (1 + rent)\n",
    "#assigns unknown TENUR to renters\n",
    "\n",
    "# Apply\n",
    "census2022['SHELCO'] = census2022.apply(adjust_shelco, axis=1)\n",
    "print(census2022[['SHELCO', 'mmr']].head())  # Check values after growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SHELCO          mmr\n",
      "0  210.526316   947.368421\n",
      "1  822.875193  1789.473684\n",
      "2  822.875193  1789.473684\n",
      "3  822.875193  1789.473684\n",
      "4  822.875193  1789.473684\n"
     ]
    }
   ],
   "source": [
    "#increase mmr variable by the 2022 rent variable in the growth df\n",
    "census2022['mmr'] = census2022['mmr']*(1+growth.loc[growth['year'] == year_to_use, 'rent'].values[0])\n",
    "print(census2022[['SHELCO', 'mmr']].head()) #check values after growing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create 2023 and 2024 census df, apply population adjustments, market and transfer income growth rates, shelter costs growth rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HH_ID     PP_ID   TOTINC  quintile\n",
      "0    1.0   11101.0  12000.0       1.0\n",
      "1    6.0   61101.0   3000.0       3.0\n",
      "2    6.0   61102.0   8000.0       3.0\n",
      "3    6.0   61103.0  69000.0       3.0\n",
      "4    6.0   61104.0      0.0       3.0\n",
      "5   13.0  131101.0  63000.0       3.0\n",
      "6   13.0  131102.0  41000.0       3.0\n",
      "7   13.0  131103.0      0.0       3.0\n",
      "8   13.0  131104.0      0.0       3.0\n",
      "9   15.0  151101.0   5000.0       1.0\n",
      "       SHELCO          mmr\n",
      "0  225.563910  1015.037594\n",
      "1  850.482897  1917.293233\n",
      "2  850.482897  1917.293233\n",
      "3  850.482897  1917.293233\n",
      "4  850.482897  1917.293233\n"
     ]
    }
   ],
   "source": [
    "# Creating 2023 microsimulation\n",
    "census2023 = census2022.copy()\n",
    "# Verify the result\n",
    "print(census2023[[\"HH_ID\", \"PP_ID\", \"TOTINC\", \"quintile\"]].head(10))\n",
    "\n",
    "#adj weights for pop growth\n",
    "# Filter to 2023 growth rates, now including 'econ'\n",
    "growth_rates_2023 = popproj[['demo', 'agegrp', 'econ', 2023]]\n",
    "# Create the 2023 growth rate lookup dictionary\n",
    "growth_rate_lookup_2023 = {\n",
    "    (row['agegrp'], row['demo'], row['econ']): row[2023]\n",
    "    for _, row in growth_rates_2023.iterrows()\n",
    "}\n",
    "# Apply the 2023 growth rates\n",
    "def apply_growth_2023(row):\n",
    "    agegrp_code = row['AGEGRP']\n",
    "    immstat = row['IMMSTAT']\n",
    "    econ = row['econ']  # Include ECON in the logic\n",
    "    agegrp_label = agegrp_mapping.get(agegrp_code, None)\n",
    "    \n",
    "    if agegrp_label is None:\n",
    "        print(f\"Warning: Unknown AGEGRP code {agegrp_code} in row {row.name}\")\n",
    "        return row  # Skip updating this row\n",
    "    demo = 'npr' if immstat == 3 else 'nonnpr'\n",
    "    \n",
    "    # Lookup the growth rate, defaulting to 1 if not found\n",
    "    growth_rate = growth_rate_lookup_2023.get((agegrp_label, demo, econ), 1)\n",
    "    \n",
    "    row['WEIGHT'] *= (1 + growth_rate)\n",
    "    return row\n",
    "# Apply the updated function to census2023\n",
    "census2023 = census2023.apply(apply_growth_2023, axis=1)\n",
    "\n",
    "def adjust_mrkinc(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq1_2023'])*0.9973\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq2_2023'])*0.9985\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq3_2023'])*0.9996\n",
    "    elif row['quintile'] == 4:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq4_2023'])\n",
    "    elif row['quintile'] == 5:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq5_2023'])\n",
    "    else:\n",
    "        return row['MRKINC']  # Default case if quintile is missing\n",
    "# Apply function row-wise\n",
    "census2023.loc[:, 'MRKINC'] = census2023.apply(adjust_mrkinc, axis=1).astype('float64')\n",
    "\n",
    "def adjust_gtrfs(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq1_2023'])*1.0125\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq2_2023'])*1.0028\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq3_2023'])*1.0020\n",
    "    elif row['quintile'] == 4:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq4_2023'])\n",
    "    elif row['quintile'] == 5:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq5_2023'])\n",
    "    else:\n",
    "        return row['GTRFS']  # Default case if quintile is missing\n",
    "# Apply function row-wise\n",
    "census2023.loc[:, 'GTRFS'] = census2023.apply(adjust_gtrfs, axis=1).astype('float64')\n",
    "\n",
    "#new variable for total income (after growing MRKINC and GTRFS)\n",
    "census2023[\"totalincome\"] = census2023[\"MRKINC\"] + census2023[\"GTRFS\"]\n",
    "census2023[\"totaltransfers\"] = census2023[\"GTRFS\"]\n",
    "\n",
    "#update shelco & mmr for 2023\n",
    "year_to_use = 2023  \n",
    "census2023['SHELCO'] = census2023.apply(adjust_shelco, axis=1)\n",
    "census2023['mmr'] = census2023['mmr']*(1+growth.loc[growth['year'] == year_to_use, 'rent'].values[0])\n",
    "print(census2023[['SHELCO', 'mmr']].head())  # Check values after growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HH_ID     PP_ID   TOTINC  quintile\n",
      "0    1.0   11101.0  12000.0       1.0\n",
      "1    6.0   61101.0   3000.0       3.0\n",
      "2    6.0   61102.0   8000.0       3.0\n",
      "3    6.0   61103.0  69000.0       3.0\n",
      "4    6.0   61104.0      0.0       3.0\n",
      "5   13.0  131101.0  63000.0       3.0\n",
      "6   13.0  131102.0  41000.0       3.0\n",
      "7   13.0  131103.0      0.0       3.0\n",
      "8   13.0  131104.0      0.0       3.0\n",
      "9   15.0  151101.0   5000.0       1.0\n",
      "       SHELCO          mmr\n",
      "0  237.593985  1069.172932\n",
      "1  886.934831  2019.548872\n",
      "2  886.934831  2019.548872\n",
      "3  886.934831  2019.548872\n",
      "4  886.934831  2019.548872\n"
     ]
    }
   ],
   "source": [
    "# Creating 2024 microsimulation\n",
    "census2024 = census2023.copy()\n",
    "# Verify the result\n",
    "print(census2024[[\"HH_ID\", \"PP_ID\", \"TOTINC\", \"quintile\"]].head(10))\n",
    "\n",
    "#adj weights for pop growth\n",
    "# Filter to 2024 growth rates, now including 'econ'\n",
    "growth_rates_2024 = popproj[['demo', 'agegrp', 'econ', 2024]]\n",
    "# Create the 2024 growth rate lookup dictionary\n",
    "growth_rate_lookup_2024 = {\n",
    "    (row['agegrp'], row['demo'], row['econ']): row[2024]\n",
    "    for _, row in growth_rates_2024.iterrows()\n",
    "}\n",
    "# Apply the 2024 growth rates\n",
    "def apply_growth_2024(row):\n",
    "    agegrp_code = row['AGEGRP']\n",
    "    immstat = row['IMMSTAT']\n",
    "    econ = row['econ']  # Include ECON in the logic\n",
    "    agegrp_label = agegrp_mapping.get(agegrp_code, None)\n",
    "    \n",
    "    if agegrp_label is None:\n",
    "        print(f\"Warning: Unknown AGEGRP code {agegrp_code} in row {row.name}\")\n",
    "        return row  # Skip updating this row\n",
    "    demo = 'npr' if immstat == 3 else 'nonnpr'\n",
    "    \n",
    "    # Lookup the growth rate, defaulting to 1 if not found\n",
    "    growth_rate = growth_rate_lookup_2024.get((agegrp_label, demo, econ), 1)\n",
    "    \n",
    "    row['WEIGHT'] *= (1 + growth_rate)\n",
    "    return row\n",
    "# Apply the updated function to census2024\n",
    "census2024 = census2024.apply(apply_growth_2024, axis=1)\n",
    "\n",
    "def adjust_mrkinc(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq1_2024'])*0.9946\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq2_2024'])*0.9967\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq3_2024'])*0.9989\n",
    "    elif row['quintile'] == 4:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq4_2024'])\n",
    "    elif row['quintile'] == 5:\n",
    "        return row['MRKINC'] * (1 + growth_rates['canada_compq5_2024'])\n",
    "    else:\n",
    "        return row['MRKINC']  # Default case if quintile is missing\n",
    "# Apply function row-wise\n",
    "census2024.loc[:, 'MRKINC'] = census2024.apply(adjust_mrkinc, axis=1).astype('float64')\n",
    "\n",
    "def adjust_gtrfs(row):\n",
    "    if row['quintile'] == 1:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq1_2024'])*1.0191\n",
    "    elif row['quintile'] == 2:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq2_2024'])*1.0056\n",
    "    elif row['quintile'] == 3:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq3_2024'])*1.0045\n",
    "    elif row['quintile'] == 4:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq4_2024'])\n",
    "    elif row['quintile'] == 5:\n",
    "        return row['GTRFS'] * (1 + growth_rates['canada_tranrq5_2024'])\n",
    "    else:\n",
    "        return row['GTRFS']  # Default case if quintile is missing\n",
    "# Apply function row-wise\n",
    "census2024.loc[:, 'GTRFS'] = census2024.apply(adjust_gtrfs, axis=1).astype('float64')\n",
    "\n",
    "#new variable for total income (after growing MRKINC and GTRFS)\n",
    "census2024[\"totalincome\"] = census2024[\"MRKINC\"] + census2024[\"GTRFS\"]\n",
    "census2024[\"totaltransfers\"] = census2024[\"GTRFS\"]\n",
    "\n",
    "#update shelco & mmr for 2024\n",
    "year_to_use = 2024  \n",
    "census2024['SHELCO'] = census2024.apply(adjust_shelco, axis=1)\n",
    "census2024['mmr'] = census2024['mmr']*(1+growth.loc[growth['year'] == year_to_use, 'rent'].values[0])\n",
    "print(census2024[['SHELCO', 'mmr']].head())  # Check values after growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Average Income Growth by Quintile ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "quintile",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mrkinc_growth_22_23 (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mrkinc_growth_23_24 (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tran_growth_22_23 (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tran_growth_23_24 (%)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "724c08b9-5352-4244-be5a-0083a82edd8d",
       "rows": [
        [
         "0",
         "1.0",
         "5.288169706298218",
         "0.21077159515845434",
         "-1.1002207361590632",
         "4.176068339895944"
        ],
        [
         "1",
         "2.0",
         "2.9237640899282935",
         "6.117846088285872",
         "0.5997082605974091",
         "4.344358700781359"
        ],
        [
         "2",
         "3.0",
         "2.5071195055413886",
         "5.981994142704439",
         "4.4617890470919574",
         "4.856758593126198"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quintile</th>\n",
       "      <th>mrkinc_growth_22_23 (%)</th>\n",
       "      <th>mrkinc_growth_23_24 (%)</th>\n",
       "      <th>tran_growth_22_23 (%)</th>\n",
       "      <th>tran_growth_23_24 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.288170</td>\n",
       "      <td>0.210772</td>\n",
       "      <td>-1.100221</td>\n",
       "      <td>4.176068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.923764</td>\n",
       "      <td>6.117846</td>\n",
       "      <td>0.599708</td>\n",
       "      <td>4.344359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.507120</td>\n",
       "      <td>5.981994</td>\n",
       "      <td>4.461789</td>\n",
       "      <td>4.856759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quintile  mrkinc_growth_22_23 (%)  mrkinc_growth_23_24 (%)  \\\n",
       "0       1.0                 5.288170                 0.210772   \n",
       "1       2.0                 2.923764                 6.117846   \n",
       "2       3.0                 2.507120                 5.981994   \n",
       "\n",
       "   tran_growth_22_23 (%)  tran_growth_23_24 (%)  \n",
       "0              -1.100221               4.176068  \n",
       "1               0.599708               4.344359  \n",
       "2               4.461789               4.856759  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Step 4: Compute average income growth by quintile ===\n",
    "\n",
    "def weighted_avg(df, value_col, weight_col):\n",
    "    \"\"\"Helper function for weighted average.\"\"\"\n",
    "    return (df[value_col] * df[weight_col]).sum() / df[weight_col].sum()\n",
    "\n",
    "# Prepare results storage\n",
    "growth_summary = []\n",
    "\n",
    "for q in sorted(census2022['quintile'].unique()):\n",
    "    # --- Average weighted incomes by year ---\n",
    "    avg_mrkinc_2022 = weighted_avg(census2022[census2022['quintile'] == q], 'MRKINC', 'WEIGHT')\n",
    "    avg_mrkinc_2023 = weighted_avg(census2023[census2023['quintile'] == q], 'MRKINC', 'WEIGHT')\n",
    "    avg_mrkinc_2024 = weighted_avg(census2024[census2024['quintile'] == q], 'MRKINC', 'WEIGHT')\n",
    "    \n",
    "    avg_tran_2022 = weighted_avg(census2022[census2022['quintile'] == q], 'GTRFS', 'WEIGHT')\n",
    "    avg_tran_2023 = weighted_avg(census2023[census2023['quintile'] == q], 'GTRFS', 'WEIGHT')\n",
    "    avg_tran_2024 = weighted_avg(census2024[census2024['quintile'] == q], 'GTRFS', 'WEIGHT')\n",
    "    \n",
    "    # --- Growth rates ---\n",
    "    mrkinc_growth_22_23 = (avg_mrkinc_2023 / avg_mrkinc_2022 - 1) * 100\n",
    "    mrkinc_growth_23_24 = (avg_mrkinc_2024 / avg_mrkinc_2023 - 1) * 100\n",
    "    \n",
    "    tran_growth_22_23 = (avg_tran_2023 / avg_tran_2022 - 1) * 100\n",
    "    tran_growth_23_24 = (avg_tran_2024 / avg_tran_2023 - 1) * 100\n",
    "    \n",
    "    growth_summary.append({\n",
    "        'quintile': q,\n",
    "        'mrkinc_growth_22_23 (%)': mrkinc_growth_22_23,\n",
    "        'mrkinc_growth_23_24 (%)': mrkinc_growth_23_24,\n",
    "        'tran_growth_22_23 (%)': tran_growth_22_23,\n",
    "        'tran_growth_23_24 (%)': tran_growth_23_24\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for clarity\n",
    "income_growth_summary = pd.DataFrame(growth_summary)\n",
    "\n",
    "# Display the summary table\n",
    "print(\"=== Average Income Growth by Quintile ===\")\n",
    "display(income_growth_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              cpp      ei      oas    child   social\n",
      "quintile                                            \n",
      "1.0       3220.16  322.02  4237.73   875.88  4224.84\n",
      "2.0       3643.94  536.53  3107.41  1419.57  2470.28\n",
      "3.0       2850.61  750.16  2179.88  1367.94  1676.83\n"
     ]
    }
   ],
   "source": [
    "# Define actual benefit shares by quintile\n",
    "benefit_shares = {\n",
    "    1: {\"cpp\": 0.25, \"ei\": 0.025, \"oas\": 0.329, \"child\": 0.068, \"social\": 0.328},\n",
    "    2: {\"cpp\": 0.326, \"ei\": 0.048, \"oas\": 0.278, \"child\": 0.127, \"social\": 0.221},\n",
    "    3: {\"cpp\": 0.323, \"ei\": 0.085, \"oas\": 0.247, \"child\": 0.155, \"social\": 0.190}\n",
    "}\n",
    "\n",
    "# Apply benefit shares to census2024\n",
    "for quintile, shares in benefit_shares.items():\n",
    "    for benefit, share in shares.items():\n",
    "        census2024.loc[census2024[\"quintile\"] == quintile, benefit] = (\n",
    "            share * census2024[\"GTRFS\"]\n",
    "        )\n",
    "\n",
    "# (Optional) verify totals\n",
    "print(census2024.groupby(\"quintile\")[[\"cpp\", \"ei\", \"oas\", \"child\", \"social\"]].mean().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quintile for this record: Q1\n",
      "        amount share_of_GTRFS\n",
      "GTRFS   $6,492         100.0%\n",
      "cpp     $1,623          25.0%\n",
      "ei        $162           2.5%\n",
      "oas     $2,136          32.9%\n",
      "child     $441           6.8%\n",
      "social  $2,129          32.8%\n",
      "\n",
      "Check: benefits sum vs GTRFS\n",
      "Benefits sum: $6,492\n",
      "GTRFS:        $6,492\n",
      "Diff:         $0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# columns we care about\n",
    "cols = [\"quintile\", \"GTRFS\", \"cpp\", \"ei\", \"oas\", \"child\", \"social\"]\n",
    "\n",
    "# pick a single valid row (random for reproducibility)\n",
    "row = (\n",
    "    census2024.loc[census2024[\"GTRFS\"].notna(), cols]\n",
    "    .sample(1, random_state=42)\n",
    "    .iloc[0]\n",
    ")\n",
    "\n",
    "# build a small display table\n",
    "out = pd.DataFrame({\n",
    "    \"amount\": [\n",
    "        row[\"GTRFS\"], row[\"cpp\"], row[\"ei\"], row[\"oas\"], row[\"child\"], row[\"social\"]\n",
    "    ],\n",
    "    \"share_of_GTRFS\": [\n",
    "        1.0,\n",
    "        row[\"cpp\"]   / row[\"GTRFS\"],\n",
    "        row[\"ei\"]    / row[\"GTRFS\"],\n",
    "        row[\"oas\"]   / row[\"GTRFS\"],\n",
    "        row[\"child\"] / row[\"GTRFS\"],\n",
    "        row[\"social\"]/ row[\"GTRFS\"],\n",
    "    ]\n",
    "}, index=[\"GTRFS\", \"cpp\", \"ei\", \"oas\", \"child\", \"social\"])\n",
    "\n",
    "# nice formatting\n",
    "out_fmt = out.copy()\n",
    "out_fmt[\"amount\"] = out_fmt[\"amount\"].map(lambda x: f\"${x:,.0f}\")\n",
    "out_fmt[\"share_of_GTRFS\"] = (out_fmt[\"share_of_GTRFS\"]*100).map(lambda x: f\"{x:.1f}%\")\n",
    "\n",
    "print(f\"Quintile for this record: Q{int(row['quintile'])}\")\n",
    "print(out_fmt)\n",
    "\n",
    "# (Optional) quick integrity check: benefits sum â‰ˆ GTRFS\n",
    "benefit_sum = row[\"cpp\"] + row[\"ei\"] + row[\"oas\"] + row[\"child\"] + row[\"social\"]\n",
    "print(\"\\nCheck: benefits sum vs GTRFS\")\n",
    "print(f\"Benefits sum: ${benefit_sum:,.0f}\")\n",
    "print(f\"GTRFS:        ${row['GTRFS']:,.0f}\")\n",
    "print(f\"Diff:         ${benefit_sum - row['GTRFS']:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Microsimulations for 2021-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved census data for 2021 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2021.csv\n",
      "Saved census data for 2022 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2022.csv\n",
      "Saved census data for 2023 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2023.csv\n",
      "Saved census data for 2024 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2024.csv\n"
     ]
    }
   ],
   "source": [
    "#Export Census data (2021 to 2024) to .csv\n",
    "folder_path = os.path.join(data_dir, \"Microsimulations\")\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "census_years = [2021, 2022, 2023, 2024]\n",
    "\n",
    "# Loop through each year and save the corresponding census dataset\n",
    "for year in census_years:\n",
    "    # Dynamically create the census variable name based on the year\n",
    "    census = globals().get(f\"census{year}\", None)\n",
    "    \n",
    "    if census is not None:\n",
    "        # Create the full path for saving the CSV file\n",
    "        csv_filename = f\"{folder_path}/census{year}.csv\"  # Combine folder path and filename\n",
    "\n",
    "        # Save the transformed dataset for the current year to a CSV file\n",
    "        census.to_csv(csv_filename, index=False)  # Save to CSV (without the index)\n",
    "        print(f\"Saved census data for {year} to {csv_filename}\")\n",
    "    else:\n",
    "        print(f\"Dataset for {year} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025 Onwards Growth Rates and Microsimulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           share     value\n",
      "0   social_2025g  0.014186\n",
      "1   social_2026g  0.008713\n",
      "2   social_2027g  0.009872\n",
      "3   social_2028g  0.010068\n",
      "4   social_2029g  0.010196\n",
      "5   social_2030g  0.010253\n",
      "6    child_2025g  0.037695\n",
      "7    child_2026g  0.014918\n",
      "8    child_2027g  0.015884\n",
      "9    child_2028g  0.010010\n",
      "10   child_2029g  0.010060\n",
      "11   child_2030g  0.011882\n",
      "12     cpp_2025g  0.026129\n",
      "13     cpp_2026g  0.020943\n",
      "14     cpp_2027g  0.020136\n",
      "15     cpp_2028g  0.019190\n",
      "16     cpp_2029g  0.019818\n",
      "17     cpp_2030g  0.020028\n",
      "18     oas_2025g  0.021007\n",
      "19     oas_2026g  0.019966\n",
      "20     oas_2027g  0.019038\n",
      "21     oas_2028g  0.019971\n",
      "22     oas_2029g  0.020039\n",
      "23     oas_2030g  0.019983\n",
      "24      ei_2025g  0.044031\n",
      "25      ei_2026g  0.038880\n",
      "26      ei_2027g  0.035632\n",
      "27      ei_2028g  0.024933\n",
      "28      ei_2029g  0.023125\n",
      "29      ei_2030g  0.022204\n",
      "30    comp_2025g  0.031334\n",
      "31    comp_2026g  0.027843\n",
      "32    comp_2027g  0.034874\n",
      "33    comp_2028g  0.030395\n",
      "34    comp_2029g  0.029619\n",
      "35    comp_2030g  0.028998\n"
     ]
    }
   ],
   "source": [
    "forecast_path = os.path.join(data_dir, \"income_growthrates.xlsx\")\n",
    "forecast = pd.read_excel(forecast_path)\n",
    "\n",
    "#print all forecast df values\n",
    "print(forecast)\n",
    "\n",
    "\n",
    "# Creating global object that can be referenced later\n",
    "for index, row in forecast.iterrows():\n",
    "    globals()[row['share']] = row['value'] # Assign each row's value to a global variable with the corresponding name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "popproj = pd.read_excel(file_path_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup dictionary for each year's growth rates, considering ECON\n",
    "growth_rate_lookups = {}\n",
    "\n",
    "for year in range(2022, 2031):\n",
    "    growth_rates_year = popproj[['demo', 'agegrp', 'econ', year]]\n",
    "    growth_rate_lookups[year] = {\n",
    "        (row['agegrp'], row['demo'], row['econ']): row[year]\n",
    "        for _, row in growth_rates_year.iterrows()\n",
    "    }\n",
    "\n",
    "def apply_population_growth(row, year):\n",
    "    agegrp_code = row['AGEGRP']\n",
    "    immstat = row['IMMSTAT']\n",
    "    econ = row['econ']  # Ensure ECON is included in calculations\n",
    "    \n",
    "    # Map AGEGRP code to string label\n",
    "    agegrp_label = agegrp_mapping.get(agegrp_code, None)\n",
    "    \n",
    "    if agegrp_label is None:\n",
    "        print(f\"Warning: Unknown AGEGRP code {agegrp_code} in row {row.name}\")\n",
    "        return row  # Leave the row unchanged if AGEGRP is invalid\n",
    "\n",
    "    demo = 'npr' if immstat == 3 else 'nonnpr'\n",
    "    \n",
    "    # Get the growth rate for the year, defaulting to 0% (no change) if missing\n",
    "    growth_rate = growth_rate_lookups[year].get((agegrp_label, demo, econ), 0)\n",
    "    \n",
    "    # Apply the growth rate\n",
    "    row['WEIGHT'] *= (1 + growth_rate)\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved census data for 2025 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2025.csv\n",
      "Saved census data for 2026 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2026.csv\n",
      "Saved census data for 2027 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2027.csv\n",
      "Saved census data for 2028 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2028.csv\n",
      "Saved census data for 2029 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2029.csv\n",
      "Saved census data for 2030 to C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations/census2030.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the years to loop over\n",
    "years = range(2025, 2031)  # Covers 2025 to 2030\n",
    "\n",
    "# Create a dictionary to store census data for each year\n",
    "census= {\"2024\": census2024} #start with 2024 census data\n",
    "weighted_sum_census = {}  # Dictionary to store weighted sum of MRKINC for each year\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    # Initialize the new year's census data by copying the previous year's data\n",
    "    prev_year = str(year - 1)\n",
    "    curr_year = str(year)\n",
    "    census[curr_year] = census[prev_year].copy()\n",
    "\n",
    "    census[curr_year] = census[curr_year].apply(lambda row: apply_population_growth(row, year), axis=1)\n",
    "\n",
    "    year_to_use = year\n",
    "    census[curr_year][\"SHELCO\"] = census[curr_year].apply(adjust_shelco, axis=1)\n",
    "    census[curr_year]['mmr'] = census[curr_year]['mmr']*(1+growth.loc[growth['year'] == year_to_use, 'rent'].values[0])\n",
    "\n",
    "    # Grow transfer income\n",
    "    census[curr_year][\"ei\"] *= (1 + globals()[f\"ei_{curr_year}g\"])\n",
    "    census[curr_year][\"child\"] *= (1 + globals()[f\"child_{curr_year}g\"])\n",
    "    census[curr_year][\"social\"] *= (1 + globals()[f\"social_{curr_year}g\"])\n",
    "    census[curr_year][\"cpp\"] *= (1 + globals()[f\"cpp_{curr_year}g\"])\n",
    "    census[curr_year][\"oas\"] *= (1 + globals()[f\"oas_{curr_year}g\"])\n",
    "\n",
    "    # Compute total transfers for the year\n",
    "    census[curr_year][f\"totaltransfers\"] = (\n",
    "        census[curr_year][\"ei\"] +\n",
    "        census[curr_year][\"child\"] +\n",
    "        census[curr_year][\"social\"] +\n",
    "        census[curr_year][\"cpp\"] +\n",
    "        census[curr_year][\"oas\"]\n",
    "    )\n",
    "\n",
    "    # Grow market income by Canada-wide shares of total income growth for each quintile\n",
    "    #canada_compq1 = 0.7834 * globals()[f\"comp_{curr_year}g\"]\n",
    "    #canada_compq2 = 0.9956 * globals()[f\"comp_{curr_year}g\"]\n",
    "    #canada_compq3 = 1.0034* globals()[f\"comp_{curr_year}g\"]\n",
    "\n",
    "    canada_compq1 = 1 * globals()[f\"comp_{curr_year}g\"]\n",
    "    canada_compq2 = 1 * globals()[f\"comp_{curr_year}g\"]\n",
    "    canada_compq3 = 1* globals()[f\"comp_{curr_year}g\"]\n",
    "\n",
    "\n",
    "\n",
    "    census[curr_year].loc[census[curr_year][\"quintile\"] == 1, \"MRKINC\"] *= (1 + canada_compq1)\n",
    "    census[curr_year].loc[census[curr_year][\"quintile\"] == 2, \"MRKINC\"] *= (1 + canada_compq2)\n",
    "    census[curr_year].loc[census[curr_year][\"quintile\"] == 3, \"MRKINC\"] *= (1 + canada_compq3)\n",
    "    \n",
    "    #create total income variable = transfer income + market income\n",
    "    census[curr_year][\"totalincome\"] = census[curr_year][\"MRKINC\"] + census[curr_year][\"totaltransfers\"]\n",
    "\n",
    "    # Create the full path for saving the CSV file\n",
    "    csv_filename = f\"{folder_path}/census{curr_year}.csv\"  # Combine folder path and filename\n",
    "\n",
    "    # Save the transformed dataset for the current year to a CSV file\n",
    "    census[curr_year].to_csv(csv_filename, index=False)  # Save to CSV (without the index)\n",
    "    print(f\"Saved census data for {curr_year} to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2024\n",
      "   IMMSTAT  AGEGRP      WEIGHT\n",
      "0      1.0    11.0  100.633283\n",
      "Year: 2025\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  99.819366\n",
      "Year: 2026\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  99.072799\n",
      "Year: 2027\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  98.048539\n",
      "Year: 2028\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  96.737103\n",
      "Year: 2029\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  95.309341\n",
      "Year: 2030\n",
      "   IMMSTAT  AGEGRP     WEIGHT\n",
      "0      1.0    11.0  94.242491\n",
      "[np.float64(100.63328345763732), np.float64(99.81936623368422), np.float64(99.07279911313402), np.float64(98.04853896345261), np.float64(96.7371030079933), np.float64(95.30934060998946), np.float64(94.24249055375437)]\n",
      "[np.float64(-0.8087952573819428), np.float64(-0.74791811320704), np.float64(-1.033845978765351), np.float64(-1.3375374781955207), np.float64(-1.4759201522562246), np.float64(-1.1193551958361567)]\n"
     ]
    }
   ],
   "source": [
    "#check weights were applied properly for first record\n",
    "\n",
    "\n",
    "#print the variables IMMSTAT, AGEGRP, WEIGHT for the first each record in each censusdf then calculate the percent change in the printed WEIGHT value\n",
    "for year, df in census.items():\n",
    "    print(f\"Year: {year}\")\n",
    "    print(df[['IMMSTAT', 'AGEGRP', 'WEIGHT']].head(1))\n",
    "\n",
    "#create an array out of each printed WEIGHT value from the previous loop\n",
    "weights = [df['WEIGHT'].values[0] for df in census.values()]\n",
    "\n",
    "\n",
    "#print weights array\n",
    "print(weights)\n",
    "\n",
    "#calculate the percent change in the values in the weights array\n",
    "percent_change = [(weights[i] - weights[i - 1]) / weights[i - 1] * 100 for i in range(1, len(weights))]\n",
    "print(percent_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create trace file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created transposed summary Excel file with years as columns at C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\census_trace.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the years you want to include\n",
    "years = range(2021, 2031)\n",
    "\n",
    "# List to hold second rows\n",
    "second_rows = []\n",
    "\n",
    "for year in years:\n",
    "    file_path = os.path.join(folder_path, f\"census{year}.csv\")\n",
    "    \n",
    "    try:\n",
    "        # Read the full CSV and select the second row (index 1)\n",
    "        second_row = pd.read_csv(file_path).iloc[[0]].copy()\n",
    "        \n",
    "        # Add a 'year' column\n",
    "        second_row['year'] = year\n",
    "        \n",
    "        # Append to the list\n",
    "        second_rows.append(second_row)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {file_path}\")\n",
    "        continue\n",
    "    except IndexError:\n",
    "        print(f\"File {file_path} does not have a second row.\")\n",
    "        continue\n",
    "\n",
    "# Combine all second rows into one DataFrame\n",
    "summary_df = pd.concat(second_rows, ignore_index=True)\n",
    "\n",
    "# Define the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    'year', 'HH_ID', 'PP_ID', 'SHELCO', 'TENUR', 'PRESMORTG', 'AGEGRP', 'quintile', \n",
    "    'totalincome', 'totaltransfers', 'social', 'cpp', \n",
    "    'ei', 'oas', 'child', 'MRKINC', 'GTRFS', 'WEIGHT', 'IMMSTAT', 'econ'\n",
    "]\n",
    "\n",
    "# Keep only the desired columns (ignore missing ones)\n",
    "summary_df = summary_df[[col for col in columns_to_keep if col in summary_df.columns]]\n",
    "\n",
    "# Set 'year' as the index\n",
    "summary_df.set_index('year', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "summary_transposed = summary_df.transpose()\n",
    "\n",
    "# Save the transposed DataFrame to Excel\n",
    "output_path = os.path.join(folder_path, f\"census_trace.xlsx\")\n",
    "summary_transposed.to_excel(output_path)\n",
    "\n",
    "print(f\"Created transposed summary Excel file with years as columns at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved household-level simulation for 2021 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2021_household.csv\n",
      "Saved household-level simulation for 2022 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2022_household.csv\n",
      "Saved household-level simulation for 2023 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2023_household.csv\n",
      "Saved household-level simulation for 2024 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2024_household.csv\n",
      "Saved household-level simulation for 2025 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2025_household.csv\n",
      "Saved household-level simulation for 2026 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2026_household.csv\n",
      "Saved household-level simulation for 2027 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2027_household.csv\n",
      "Saved household-level simulation for 2028 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2028_household.csv\n",
      "Saved household-level simulation for 2029 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2029_household.csv\n",
      "Saved household-level simulation for 2030 -> C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household/census2030_household.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = folder_path\n",
    "output_folder = os.path.join(folder_path, \"household\")\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define years for processing\n",
    "years = range(2021, 2031)  # Covers 2023 to 2030\n",
    "\n",
    "# Loop through each year's census simulation file\n",
    "for year in years:\n",
    "    input_file = f\"{input_folder}/census{year}.csv\"\n",
    "    output_file = f\"{output_folder}/census{year}_household.csv\"\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Skipping {year}: File not found -> {input_file}\")\n",
    "        continue\n",
    "\n",
    "    # Load individual-level census data\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Compute average WEIGHT for adults (AGEGRP > 2)\n",
    "    adult_weights = df[df[\"AGEGRP\"] > 2].groupby(\"HH_ID\")[\"WEIGHT\"].mean().reset_index()\n",
    "    adult_weights.rename(columns={\"WEIGHT\": \"avg_adult_weight\"}, inplace=True)\n",
    "\n",
    "    # Group by HH_ID and aggregate\n",
    "    household_df = df.groupby(\"HH_ID\").agg({\n",
    "        \"BEDRM\": \"first\",\n",
    "        \"HCORENEED_IND\": \"first\",\n",
    "        \"REPAIR\": \"first\",\n",
    "        \"NOS\": \"first\",\n",
    "        \"PRESMORTG\": \"first\",\n",
    "        \"SHELCO\": \"first\",\n",
    "        \"TENUR\": \"first\",\n",
    "        \"SUBSIDY\": \"first\",\n",
    "        \"quintile\": \"first\",\n",
    "        \"totalincome\": \"sum\",\n",
    "        \"MRKINC\": \"sum\",\n",
    "        \"TOTINC_AT\": \"sum\",\n",
    "        \"totaltransfers\": \"sum\",\n",
    "        \"mmr\":\"first\",\n",
    "        \"student_household\": \"first\",\n",
    "        \"non_family_household\": \"first\",\n",
    "        \"chn\":\"first\",\n",
    "         \"dchn\":\"first\",\n",
    "        \"bedsuit\":\"first\",\n",
    "        \"stir\" : \"first\"\n",
    "    }).reset_index()\n",
    "\n",
    "   # Merge average adult weight into the household-level dataframe\n",
    "    household_df = household_df.merge(adult_weights, on=\"HH_ID\", how=\"left\")\n",
    "\n",
    "   # Rename the merged column to WEIGHT\n",
    "    household_df.rename(columns={\"avg_adult_weight\": \"WEIGHT\"}, inplace=True)\n",
    "\n",
    "    # Save the transformed household-level data\n",
    "    household_df.to_csv(output_file, index=False)\n",
    "\n",
    "    ###To do: gross up weights to align with FAO household projection###\n",
    "    \n",
    "    print(f\"Saved household-level simulation for {year} -> {output_file}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created transposed summary Excel file with years as columns at C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\household\\census_trace_hh.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the years you want to include\n",
    "years = range(2021, 2031)\n",
    "\n",
    "# List to hold second rows\n",
    "second_rows = []\n",
    "\n",
    "for year in years:\n",
    "    file_path = os.path.join(folder_path, \"household\", f\"census{year}_household.csv\")\n",
    "    \n",
    "    try:\n",
    "        # Read the full CSV and select the second row (index 1)\n",
    "        second_row = pd.read_csv(file_path).iloc[[0]].copy()\n",
    "        \n",
    "        # Add a 'year' column\n",
    "        second_row['year'] = year\n",
    "        \n",
    "        # Append to the list\n",
    "        second_rows.append(second_row)\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {file_path}\")\n",
    "        continue\n",
    "    except IndexError:\n",
    "        print(f\"File {file_path} does not have a second row.\")\n",
    "        continue\n",
    "\n",
    "# Combine all second rows into one DataFrame\n",
    "summary_df = pd.concat(second_rows, ignore_index=True)\n",
    "\n",
    "# Define the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    'year', 'HH_ID','SHELCO', 'NOS', 'REPAIR', 'BEDRM', 'TENUR', 'PRESMORTG', 'AGEGRP' 'quintile', \n",
    "    'totalincome', 'totaltransfers', 'MRKINC', 'GTRFS', \"WEIGHT\"\n",
    "]\n",
    "\n",
    "# Keep only the desired columns (ignore missing ones)\n",
    "summary_df = summary_df[[col for col in columns_to_keep if col in summary_df.columns]]\n",
    "\n",
    "# Set 'year' as the index\n",
    "summary_df.set_index('year', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "summary_transposed = summary_df.transpose()\n",
    "\n",
    "# Save the transposed DataFrame to Excel\n",
    "output_path = os.path.join(folder_path, \"household\", \"census_trace_hh.xlsx\")\n",
    "summary_transposed.to_excel(output_path)\n",
    "\n",
    "print(f\"Created transposed summary Excel file with years as columns at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Year-over-Year Per-Household MRKINC Growth by Quintile ---\n",
      "\n",
      "Quintile 1:\n",
      "Year 2022 | Avg HH MRKINC YoY Growth: 1.24%\n",
      "Year 2023 | Avg HH MRKINC YoY Growth: 5.77%\n",
      "Year 2024 | Avg HH MRKINC YoY Growth: 0.73%\n",
      "Year 2025 | Avg HH MRKINC YoY Growth: 2.57%\n",
      "Year 2026 | Avg HH MRKINC YoY Growth: 2.21%\n",
      "Year 2027 | Avg HH MRKINC YoY Growth: 2.93%\n",
      "Year 2028 | Avg HH MRKINC YoY Growth: 2.69%\n",
      "Year 2029 | Avg HH MRKINC YoY Growth: 2.62%\n",
      "Year 2030 | Avg HH MRKINC YoY Growth: 2.58%\n",
      "\n",
      "Quintile 2:\n",
      "Year 2022 | Avg HH MRKINC YoY Growth: 3.94%\n",
      "Year 2023 | Avg HH MRKINC YoY Growth: 2.87%\n",
      "Year 2024 | Avg HH MRKINC YoY Growth: 6.32%\n",
      "Year 2025 | Avg HH MRKINC YoY Growth: 2.71%\n",
      "Year 2026 | Avg HH MRKINC YoY Growth: 2.39%\n",
      "Year 2027 | Avg HH MRKINC YoY Growth: 3.11%\n",
      "Year 2028 | Avg HH MRKINC YoY Growth: 2.83%\n",
      "Year 2029 | Avg HH MRKINC YoY Growth: 2.73%\n",
      "Year 2030 | Avg HH MRKINC YoY Growth: 2.67%\n",
      "\n",
      "Quintile 3:\n",
      "Year 2022 | Avg HH MRKINC YoY Growth: 6.81%\n",
      "Year 2023 | Avg HH MRKINC YoY Growth: 2.32%\n",
      "Year 2024 | Avg HH MRKINC YoY Growth: 6.20%\n",
      "Year 2025 | Avg HH MRKINC YoY Growth: 2.95%\n",
      "Year 2026 | Avg HH MRKINC YoY Growth: 2.61%\n",
      "Year 2027 | Avg HH MRKINC YoY Growth: 3.32%\n",
      "Year 2028 | Avg HH MRKINC YoY Growth: 2.94%\n",
      "Year 2029 | Avg HH MRKINC YoY Growth: 2.85%\n",
      "Year 2030 | Avg HH MRKINC YoY Growth: 2.79%\n",
      "\n",
      "--- Year-over-Year Per-Household Total Transfers Growth by Quintile ---\n",
      "\n",
      "Quintile 1:\n",
      "Year 2022 | Avg HH Transfers YoY Growth: -0.40%\n",
      "Year 2023 | Avg HH Transfers YoY Growth: -0.68%\n",
      "Year 2024 | Avg HH Transfers YoY Growth: 4.64%\n",
      "Year 2025 | Avg HH Transfers YoY Growth: 3.30%\n",
      "Year 2026 | Avg HH Transfers YoY Growth: 2.76%\n",
      "Year 2027 | Avg HH Transfers YoY Growth: 2.72%\n",
      "Year 2028 | Avg HH Transfers YoY Growth: 1.99%\n",
      "Year 2029 | Avg HH Transfers YoY Growth: 2.01%\n",
      "Year 2030 | Avg HH Transfers YoY Growth: 1.99%\n",
      "\n",
      "Quintile 2:\n",
      "Year 2022 | Avg HH Transfers YoY Growth: -2.42%\n",
      "Year 2023 | Avg HH Transfers YoY Growth: 0.46%\n",
      "Year 2024 | Avg HH Transfers YoY Growth: 4.18%\n",
      "Year 2025 | Avg HH Transfers YoY Growth: 3.09%\n",
      "Year 2026 | Avg HH Transfers YoY Growth: 2.40%\n",
      "Year 2027 | Avg HH Transfers YoY Growth: 2.35%\n",
      "Year 2028 | Avg HH Transfers YoY Growth: 1.96%\n",
      "Year 2029 | Avg HH Transfers YoY Growth: 2.00%\n",
      "Year 2030 | Avg HH Transfers YoY Growth: 2.01%\n",
      "\n",
      "Quintile 3:\n",
      "Year 2022 | Avg HH Transfers YoY Growth: -7.64%\n",
      "Year 2023 | Avg HH Transfers YoY Growth: 4.14%\n",
      "Year 2024 | Avg HH Transfers YoY Growth: 4.43%\n",
      "Year 2025 | Avg HH Transfers YoY Growth: 3.16%\n",
      "Year 2026 | Avg HH Transfers YoY Growth: 2.42%\n",
      "Year 2027 | Avg HH Transfers YoY Growth: 2.36%\n",
      "Year 2028 | Avg HH Transfers YoY Growth: 1.96%\n",
      "Year 2029 | Avg HH Transfers YoY Growth: 2.00%\n",
      "Year 2030 | Avg HH Transfers YoY Growth: 2.02%\n",
      "\n",
      "--- Year-over-Year Per-Household Total Income Growth by Quintile ---\n",
      "\n",
      "Quintile 1:\n",
      "Year 2022 | Avg HH Total Income YoY Growth: 0.17%\n",
      "Year 2023 | Avg HH Total Income YoY Growth: 1.57%\n",
      "Year 2024 | Avg HH Total Income YoY Growth: 3.22%\n",
      "Year 2025 | Avg HH Total Income YoY Growth: 3.04%\n",
      "Year 2026 | Avg HH Total Income YoY Growth: 2.57%\n",
      "Year 2027 | Avg HH Total Income YoY Growth: 2.80%\n",
      "Year 2028 | Avg HH Total Income YoY Growth: 2.24%\n",
      "Year 2029 | Avg HH Total Income YoY Growth: 2.22%\n",
      "Year 2030 | Avg HH Total Income YoY Growth: 2.20%\n",
      "\n",
      "Quintile 2:\n",
      "Year 2022 | Avg HH Total Income YoY Growth: 1.51%\n",
      "Year 2023 | Avg HH Total Income YoY Growth: 1.99%\n",
      "Year 2024 | Avg HH Total Income YoY Growth: 5.55%\n",
      "Year 2025 | Avg HH Total Income YoY Growth: 2.84%\n",
      "Year 2026 | Avg HH Total Income YoY Growth: 2.40%\n",
      "Year 2027 | Avg HH Total Income YoY Growth: 2.84%\n",
      "Year 2028 | Avg HH Total Income YoY Growth: 2.52%\n",
      "Year 2029 | Avg HH Total Income YoY Growth: 2.47%\n",
      "Year 2030 | Avg HH Total Income YoY Growth: 2.44%\n",
      "\n",
      "Quintile 3:\n",
      "Year 2022 | Avg HH Total Income YoY Growth: 3.26%\n",
      "Year 2023 | Avg HH Total Income YoY Growth: 2.72%\n",
      "Year 2024 | Avg HH Total Income YoY Growth: 5.81%\n",
      "Year 2025 | Avg HH Total Income YoY Growth: 2.99%\n",
      "Year 2026 | Avg HH Total Income YoY Growth: 2.57%\n",
      "Year 2027 | Avg HH Total Income YoY Growth: 3.11%\n",
      "Year 2028 | Avg HH Total Income YoY Growth: 2.73%\n",
      "Year 2029 | Avg HH Total Income YoY Growth: 2.67%\n",
      "Year 2030 | Avg HH Total Income YoY Growth: 2.62%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the years and quintiles\n",
    "years = range(2021, 2031)\n",
    "quintiles = [1, 2, 3]\n",
    "\n",
    "# Dictionaries to store weighted sums and weighted counts by year and quintile\n",
    "weighted_HH_MRKINC = {year: {} for year in years}\n",
    "weighted_HH_transfers = {year: {} for year in years}\n",
    "weighted_HH_totalincome = {year: {} for year in years}  # NEW for totalincome\n",
    "weighted_HH_counts = {year: {} for year in years}  # To store sum of weights per quintile\n",
    "\n",
    "# Loop through each year and calculate weighted sums & counts by quintile\n",
    "for year in years:\n",
    "    file_path = os.path.join(folder_path, \"household\", f\"census{year}_household.csv\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Ensure household-level aggregation by taking the first value per HH_ID\n",
    "        df_household = df.groupby(\"HH_ID\").agg(\n",
    "            {\n",
    "                \"MRKINC\": \"first\",\n",
    "                \"totaltransfers\": \"first\",\n",
    "                \"totalincome\": \"first\",  # NEW: Add totalincome\n",
    "                \"WEIGHT\": \"first\",\n",
    "                \"quintile\": \"first\"\n",
    "            }\n",
    "        ).reset_index()\n",
    "\n",
    "        for q in quintiles:\n",
    "            df_q = df_household[df_household[\"quintile\"] == q]\n",
    "            \n",
    "            # Calculate weighted sums\n",
    "            weighted_HH_MRKINC[year][q] = (df_q[\"MRKINC\"] * df_q[\"WEIGHT\"]).sum()\n",
    "            weighted_HH_transfers[year][q] = (df_q[\"totaltransfers\"] * df_q[\"WEIGHT\"]).sum()\n",
    "            weighted_HH_totalincome[year][q] = (df_q[\"totalincome\"] * df_q[\"WEIGHT\"]).sum()  # NEW: Total income\n",
    "            \n",
    "            # Calculate total weight (sum of weights) per quintile\n",
    "            weighted_HH_counts[year][q] = df_q[\"WEIGHT\"].sum()\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {file_path}\")\n",
    "        continue\n",
    "\n",
    "# Compute per-household weighted averages\n",
    "avg_HH_MRKINC = {\n",
    "    year: {q: (weighted_HH_MRKINC[year][q] / weighted_HH_counts[year][q]) if weighted_HH_counts[year][q] != 0 else None for q in quintiles}\n",
    "    for year in years\n",
    "}\n",
    "avg_HH_transfers = {\n",
    "    year: {q: (weighted_HH_transfers[year][q] / weighted_HH_counts[year][q]) if weighted_HH_counts[year][q] != 0 else None for q in quintiles}\n",
    "    for year in years\n",
    "}\n",
    "avg_HH_totalincome = {  # NEW: Compute avg for total income\n",
    "    year: {q: (weighted_HH_totalincome[year][q] / weighted_HH_counts[year][q]) if weighted_HH_counts[year][q] != 0 else None for q in quintiles}\n",
    "    for year in years\n",
    "}\n",
    "\n",
    "# Print Year-over-Year Growth for Household Market Income (MRKINC)\n",
    "print(\"\\n--- Year-over-Year Per-Household MRKINC Growth by Quintile ---\")\n",
    "for q in quintiles:\n",
    "    print(f\"\\nQuintile {q}:\")\n",
    "    for year in range(2022, 2031):  # Start from 2023 since we compare against the previous year\n",
    "        prev = avg_HH_MRKINC.get(year - 1, {}).get(q)\n",
    "        curr = avg_HH_MRKINC.get(year, {}).get(q)\n",
    "        growth = ((curr - prev) / prev) * 100 if prev is not None and prev != 0 else None\n",
    "        print(f\"Year {year} | Avg HH MRKINC YoY Growth: {growth:.2f}%\" if growth is not None else f\"Year {year} | Avg HH MRKINC YoY Growth: N/A\")\n",
    "\n",
    "# Print Year-over-Year Growth for Household Total Transfers\n",
    "print(\"\\n--- Year-over-Year Per-Household Total Transfers Growth by Quintile ---\")\n",
    "for q in quintiles:\n",
    "    print(f\"\\nQuintile {q}:\")\n",
    "    for year in range(2022, 2031):\n",
    "        prev = avg_HH_transfers.get(year - 1, {}).get(q)\n",
    "        curr = avg_HH_transfers.get(year, {}).get(q)\n",
    "        growth = ((curr - prev) / prev) * 100 if prev is not None and prev != 0 else None\n",
    "        print(f\"Year {year} | Avg HH Transfers YoY Growth: {growth:.2f}%\" if growth is not None else f\"Year {year} | Avg HH Transfers YoY Growth: N/A\")\n",
    "\n",
    "# Print Year-over-Year Growth for Household Total Income\n",
    "print(\"\\n--- Year-over-Year Per-Household Total Income Growth by Quintile ---\")\n",
    "for q in quintiles:\n",
    "    print(f\"\\nQuintile {q}:\")\n",
    "    for year in range(2022, 2031):\n",
    "        prev = avg_HH_totalincome.get(year - 1, {}).get(q)\n",
    "        curr = avg_HH_totalincome.get(year, {}).get(q)\n",
    "        growth = ((curr - prev) / prev) * 100 if prev is not None and prev != 0 else None\n",
    "        print(f\"Year {year} | Avg HH Total Income YoY Growth: {growth:.2f}%\" if growth is not None else f\"Year {year} | Avg HH Total Income YoY Growth: N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Weighted Average Household Benefit Values for Quintile 1 ---\n",
      "\n",
      "Year 2024:\n",
      "  Social Benefit: 6,023.20\n",
      "  Cpp Benefit: 4,590.85\n",
      "  Ei Benefit: 459.09\n",
      "  Oas Benefit: 6,041.56\n",
      "  Child Benefit: 1,248.71\n",
      "  Totaltransfers Benefit: 18,363.40\n",
      "\n",
      "Year 2025:\n",
      "  Social Benefit: 6,177.51\n",
      "  Cpp Benefit: 4,763.92\n",
      "  Ei Benefit: 484.70\n",
      "  Oas Benefit: 6,238.02\n",
      "  Child Benefit: 1,310.39\n",
      "  Totaltransfers Benefit: 18,974.55\n"
     ]
    }
   ],
   "source": [
    "# Define the years and benefits of interest\n",
    "years = [2024, 2025]\n",
    "benefits = [\"social\", \"cpp\", \"ei\", \"oas\", \"child\", \"totaltransfers\"]\n",
    "\n",
    "# Dictionary to store weighted sums and counts per year\n",
    "weighted_sums = {year: {b: 0 for b in benefits} for year in years}\n",
    "total_weights = {year: 0 for year in years}\n",
    "\n",
    "# Process each year's data\n",
    "for year in years:\n",
    "    file_path = os.path.join(folder_path, f\"census{year}.csv\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Group by household (HH_ID) and aggregate:\n",
    "        df_household = df.groupby(\"HH_ID\").agg(\n",
    "            {b: \"sum\" for b in benefits} | {\"WEIGHT\": \"first\", \"quintile\": \"first\"}  # Sum benefits, keep first weight & quintile\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Filter for Quintile 1\n",
    "        df_q1 = df_household[df_household[\"quintile\"] == 1]\n",
    "        \n",
    "        # Compute weighted sums for each benefit\n",
    "        for b in benefits:\n",
    "            weighted_sums[year][b] = (df_q1[b] * df_q1[\"WEIGHT\"]).sum()\n",
    "        \n",
    "        # Compute total weight for Quintile 1\n",
    "        total_weights[year] = df_q1[\"WEIGHT\"].sum()\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for year {year}: {file_path}\")\n",
    "        continue\n",
    "\n",
    "# Compute weighted averages\n",
    "weighted_averages = {\n",
    "    year: {b: (weighted_sums[year][b] / total_weights[year]) if total_weights[year] > 0 else None for b in benefits}\n",
    "    for year in years\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\n--- Weighted Average Household Benefit Values for Quintile 1 ---\")\n",
    "for year in years:\n",
    "    print(f\"\\nYear {year}:\")\n",
    "    for b in benefits:\n",
    "        value = weighted_averages[year][b]\n",
    "        print(f\"  {b.capitalize()} Benefit: {value:,.2f}\" if value is not None else f\"  {b.capitalize()} Benefit: N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Weighted count of NPRs by household type:\n",
      "household_type\n",
      "All NPRs    170107\n",
      "Mixed        56133\n",
      "Name: WEIGHT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set input path and load data\n",
    "input_base_path = folder_path\n",
    "df = pd.read_csv(os.path.join(input_base_path, \"census2021.csv\"))\n",
    "\n",
    "# Step 1: Flag if individual is a non-permanent resident (NPR)\n",
    "df['is_npr'] = df['IMMSTAT'] == 3\n",
    "\n",
    "# Step 2: Group by HH_ID to summarize household composition\n",
    "hh_summary = df.groupby('HH_ID')['is_npr'].agg(\n",
    "    total_members='count',\n",
    "    n_nprs='sum'\n",
    ")\n",
    "hh_summary['n_non_nprs'] = hh_summary['total_members'] - hh_summary['n_nprs']\n",
    "\n",
    "# Step 3: Classify household type\n",
    "def classify_household(row):\n",
    "    if row['n_nprs'] == row['total_members']:\n",
    "        return 'All NPRs'\n",
    "    elif row['n_nprs'] == 0:\n",
    "        return 'No NPRs'\n",
    "    else:\n",
    "        return 'Mixed'\n",
    "\n",
    "hh_summary['household_type'] = hh_summary.apply(classify_household, axis=1)\n",
    "\n",
    "# Step 4: Merge back to assign each person their household type\n",
    "df = df.merge(hh_summary[['household_type']], on='HH_ID', how='left')\n",
    "\n",
    "# Step 5: Filter to only NPRs\n",
    "npr_only = df[df['IMMSTAT'] == 3]\n",
    "\n",
    "# Step 6: Weighted count of NPRs by household type\n",
    "weighted_npr_distribution = npr_only.groupby('household_type')['WEIGHT'].sum().round(0).astype(int)\n",
    "\n",
    "# Display result\n",
    "print(\"ðŸ“Š Weighted count of NPRs by household type:\")\n",
    "print(weighted_npr_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Exported NPR household IDs to: C:\\Users\\mgordon\\OneDrive - Financial Accountability Office of Ontario\\FA2404 Housing and Homelessness Update\\Data\\Microsimulations\\npr_household_ids.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get NPR household IDs (All NPRs or Mixed)\n",
    "npr_household_ids = hh_summary[hh_summary['household_type'].isin(['All NPRs', 'Mixed'])].index.tolist()\n",
    "\n",
    "# Convert to DataFrame\n",
    "npr_hh_df = pd.DataFrame(npr_household_ids, columns=['HH_ID'])\n",
    "\n",
    "# Export to CSV\n",
    "output_path = os.path.join(folder_path, \"npr_household_ids.csv\")\n",
    "npr_hh_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Exported NPR household IDs to: {os.path.normpath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
