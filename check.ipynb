{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d27c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\n",
      "Movers path: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\moversd.csv exists? True\n",
      "Census 2024 path: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2024_household_chn.csv exists? True\n",
      "Census 2025 path: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2025_household_chn.csv exists? True\n",
      "Movers HH_ID count: 176\n",
      "[2024] Total rows: 32972 | Subset rows: 176 | Unique HH_ID: 176\n",
      "[2024] Saved subset to: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\2024subsetd.csv\n",
      "[2025] Total rows: 32972 | Subset rows: 176 | Unique HH_ID: 176\n",
      "[2025] Saved subset to: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\2025subsetd.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -----------------------------\n",
    "# Load env + paths\n",
    "# -----------------------------\n",
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "if not DATA_PATH:\n",
    "    raise ValueError(\"DATA_PATH not found. Check your .env file and that load_dotenv() is running.\")\n",
    "\n",
    "movers_path = os.path.join(DATA_PATH, \"moversd.csv\")\n",
    "\n",
    "with_chn_path = os.path.join(DATA_PATH, \"Microsimulations\", \"with_chn\")\n",
    "census_2024_path = os.path.join(with_chn_path, \"census2024_household_chn.csv\")\n",
    "census_2025_path = os.path.join(with_chn_path, \"census2025_household_chn.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Sanity checks\n",
    "# -----------------------------\n",
    "print(\"DATA_PATH:\", DATA_PATH)\n",
    "print(\"Movers path:\", movers_path, \"exists?\", os.path.exists(movers_path))\n",
    "print(\"Census 2024 path:\", census_2024_path, \"exists?\", os.path.exists(census_2024_path))\n",
    "print(\"Census 2025 path:\", census_2025_path, \"exists?\", os.path.exists(census_2025_path))\n",
    "\n",
    "if not os.path.exists(movers_path):\n",
    "    raise FileNotFoundError(f\"Movers file not found: {movers_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load movers IDs (as ints)\n",
    "# -----------------------------\n",
    "movers_df = pd.read_csv(movers_path)\n",
    "\n",
    "if \"HH_ID\" not in movers_df.columns:\n",
    "    raise ValueError(\"moversd.csv is missing required column: HH_ID\")\n",
    "\n",
    "movers_ids = (\n",
    "    pd.to_numeric(movers_df[\"HH_ID\"], errors=\"coerce\")\n",
    "      .dropna()\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "# Optional: de-duplicate movers list\n",
    "movers_ids = movers_ids.drop_duplicates()\n",
    "\n",
    "print(\"Movers HH_ID count:\", len(movers_ids))\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: subset + save\n",
    "# -----------------------------\n",
    "def subset_and_save(year: int, census_path: str, movers_ids: pd.Series, out_folder: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(census_path):\n",
    "        raise FileNotFoundError(f\"[{year}] Census file not found: {census_path}\")\n",
    "\n",
    "    df = pd.read_csv(census_path)\n",
    "\n",
    "    if \"HH_ID\" not in df.columns:\n",
    "        raise ValueError(f\"[{year}] Census file missing required column: HH_ID\")\n",
    "\n",
    "    df[\"HH_ID\"] = pd.to_numeric(df[\"HH_ID\"], errors=\"coerce\")\n",
    "\n",
    "    subset = df[df[\"HH_ID\"].isin(movers_ids)].copy()\n",
    "\n",
    "    out_path = os.path.join(out_folder, f\"{year}subsetd.csv\")\n",
    "    subset.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"[{year}] Total rows: {len(df)} | Subset rows: {len(subset)} | Unique HH_ID: {subset['HH_ID'].nunique()}\")\n",
    "    print(f\"[{year}] Saved subset to: {out_path}\")\n",
    "\n",
    "    return subset\n",
    "\n",
    "# -----------------------------\n",
    "# Run for 2024 + 2025\n",
    "# -----------------------------\n",
    "subset_2024_movers = subset_and_save(2024, census_2024_path, movers_ids, DATA_PATH)\n",
    "subset_2025_movers = subset_and_save(2025, census_2025_path, movers_ids, DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e848be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved subset to: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\2024subset.csv\n"
     ]
    }
   ],
   "source": [
    "subset_out_path = os.path.join(DATA_PATH, \"2024subset.csv\")\n",
    "\n",
    "subset_2024_movers.to_csv(subset_out_path, index=False)\n",
    "\n",
    "print(\"Saved subset to:\", subset_out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a766cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\n",
      "Movers path: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\moversd.csv exists? True\n",
      "Census 2025 path: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2025_household_chn.csv exists? True\n",
      "Movers HH_ID count: 176\n",
      "Saved: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2025_household_chn_with_mover.csv\n",
      "Mover counts:\n",
      "mover\n",
      "0    32796\n",
      "1      176\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -----------------------------\n",
    "# Load env + paths\n",
    "# -----------------------------\n",
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "if not DATA_PATH:\n",
    "    raise ValueError(\"DATA_PATH not found. Check your .env file and that load_dotenv() is running.\")\n",
    "\n",
    "movers_path = os.path.join(DATA_PATH, \"moversd.csv\")\n",
    "\n",
    "with_chn_path = os.path.join(DATA_PATH, \"Microsimulations\", \"with_chn\")\n",
    "census_2025_path = os.path.join(with_chn_path, \"census2025_household_chn.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Sanity checks\n",
    "# -----------------------------\n",
    "print(\"DATA_PATH:\", DATA_PATH)\n",
    "print(\"Movers path:\", movers_path, \"exists?\", os.path.exists(movers_path))\n",
    "print(\"Census 2025 path:\", census_2025_path, \"exists?\", os.path.exists(census_2025_path))\n",
    "\n",
    "if not os.path.exists(movers_path):\n",
    "    raise FileNotFoundError(f\"Movers file not found: {movers_path}\")\n",
    "if not os.path.exists(census_2025_path):\n",
    "    raise FileNotFoundError(f\"Census 2025 file not found: {census_2025_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load movers IDs (as ints)\n",
    "# -----------------------------\n",
    "movers_df = pd.read_csv(movers_path)\n",
    "\n",
    "if \"HH_ID\" not in movers_df.columns:\n",
    "    raise ValueError(\"moversd.csv is missing required column: HH_ID\")\n",
    "\n",
    "movers_ids = (\n",
    "    pd.to_numeric(movers_df[\"HH_ID\"], errors=\"coerce\")\n",
    "      .dropna()\n",
    "      .astype(int)\n",
    "      .drop_duplicates()\n",
    ")\n",
    "\n",
    "movers_set = set(movers_ids.tolist())\n",
    "print(\"Movers HH_ID count:\", len(movers_set))\n",
    "\n",
    "# -----------------------------\n",
    "# Load 2025 census + add mover flag\n",
    "# -----------------------------\n",
    "census_2025 = pd.read_csv(census_2025_path)\n",
    "\n",
    "if \"HH_ID\" not in census_2025.columns:\n",
    "    raise ValueError(\"[2025] Census file missing required column: HH_ID\")\n",
    "\n",
    "# Keep a numeric HH_ID for matching, but don't break your file if HH_ID is stored as text\n",
    "hh_id_num = pd.to_numeric(census_2025[\"HH_ID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "census_2025[\"mover\"] = hh_id_num.isin(movers_set).astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# Save a full copy with mover flag\n",
    "# -----------------------------\n",
    "out_path = os.path.join(with_chn_path, \"census2025_household_chn_with_mover.csv\")\n",
    "census_2025.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"Mover counts:\")\n",
    "print(census_2025[\"mover\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992ae84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-mover HH_ID count: 2214\n",
      "Saved: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2024_household_chn_nonmovers.csv\n",
      "[2024] Total rows: 32972 | Subset rows: 2214 | Unique HH_ID: 2214\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "nonmovers_path = os.path.join(DATA_PATH, \"nonmoversd.csv\")\n",
    "census_2024_path = os.path.join(with_chn_path, \"census2024_household_chn.csv\")\n",
    "\n",
    "if not os.path.exists(nonmovers_path):\n",
    "    raise FileNotFoundError(f\"Non-movers file not found: {nonmovers_path}\")\n",
    "if not os.path.exists(census_2024_path):\n",
    "    raise FileNotFoundError(f\"Census 2024 file not found: {census_2024_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load non-mover HH_IDs\n",
    "# -----------------------------\n",
    "nonmovers_df = pd.read_csv(nonmovers_path)\n",
    "\n",
    "if \"HH_ID\" not in nonmovers_df.columns:\n",
    "    raise ValueError(\"nonmoversd.csv is missing required column: HH_ID\")\n",
    "\n",
    "nonmover_ids = (\n",
    "    pd.to_numeric(nonmovers_df[\"HH_ID\"], errors=\"coerce\")\n",
    "      .dropna()\n",
    "      .astype(int)\n",
    "      .drop_duplicates()\n",
    ")\n",
    "\n",
    "nonmover_set = set(nonmover_ids.tolist())\n",
    "\n",
    "print(\"Non-mover HH_ID count:\", len(nonmover_set))\n",
    "\n",
    "# -----------------------------\n",
    "# Load 2024 census + subset\n",
    "# -----------------------------\n",
    "census_2024 = pd.read_csv(census_2024_path)\n",
    "\n",
    "if \"HH_ID\" not in census_2024.columns:\n",
    "    raise ValueError(\"[2024] Census file missing required column: HH_ID\")\n",
    "\n",
    "hh_id_num = pd.to_numeric(census_2024[\"HH_ID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "subset_2024_nonmovers = census_2024[hh_id_num.isin(nonmover_set)].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Save subset\n",
    "# -----------------------------\n",
    "out_path = os.path.join(\n",
    "    with_chn_path, \"census2024_household_chn_nonmovers.csv\"\n",
    ")\n",
    "subset_2024_nonmovers.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\n",
    "    \"[2024] Total rows:\", len(census_2024),\n",
    "    \"| Subset rows:\", len(subset_2024_nonmovers),\n",
    "    \"| Unique HH_ID:\", subset_2024_nonmovers[\"HH_ID\"].nunique()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16caa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mover_flag(\n",
    "    census_path: str,\n",
    "    movers_path: str,\n",
    "    out_path: str,\n",
    "    year: int\n",
    "):\n",
    "    if not os.path.exists(census_path):\n",
    "        raise FileNotFoundError(f\"[{year}] Census file not found: {census_path}\")\n",
    "    if not os.path.exists(movers_path):\n",
    "        raise FileNotFoundError(f\"Movers file not found: {movers_path}\")\n",
    "\n",
    "    # Load movers\n",
    "    movers_df = pd.read_csv(movers_path)\n",
    "    if \"HH_ID\" not in movers_df.columns:\n",
    "        raise ValueError(\"moversd.csv missing HH_ID column\")\n",
    "\n",
    "    movers_set = set(\n",
    "        pd.to_numeric(movers_df[\"HH_ID\"], errors=\"coerce\")\n",
    "          .dropna()\n",
    "          .astype(int)\n",
    "    )\n",
    "\n",
    "    # Load census\n",
    "    df = pd.read_csv(census_path)\n",
    "    if \"HH_ID\" not in df.columns:\n",
    "        raise ValueError(f\"[{year}] Census file missing HH_ID column\")\n",
    "\n",
    "    hh_id_num = pd.to_numeric(df[\"HH_ID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Assign mover flag\n",
    "    df[\"mover\"] = hh_id_num.isin(movers_set).astype(int)\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(\n",
    "        f\"[{year}] Saved with mover flag:\",\n",
    "        out_path,\n",
    "        \"| movers flagged:\", df[\"mover\"].sum()\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b96ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024] Saved with mover flag: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2024_household_chn_with_mover.csv | movers flagged: 176\n",
      "[2025] Saved with mover flag: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2025_household_chn_with_mover.csv | movers flagged: 176\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "movers_path = os.path.join(DATA_PATH, \"moversd.csv\")\n",
    "\n",
    "census_2024_path = os.path.join(with_chn_path, \"census2024_household_chn.csv\")\n",
    "census_2025_path = os.path.join(with_chn_path, \"census2025_household_chn.csv\")\n",
    "\n",
    "out_2024 = os.path.join(\n",
    "    with_chn_path, \"census2024_household_chn_with_mover.csv\"\n",
    ")\n",
    "out_2025 = os.path.join(\n",
    "    with_chn_path, \"census2025_household_chn_with_mover.csv\"\n",
    ")\n",
    "\n",
    "# Run\n",
    "census_2024 = add_mover_flag(\n",
    "    census_2024_path, movers_path, out_2024, year=2024\n",
    ")\n",
    "\n",
    "census_2025 = add_mover_flag(\n",
    "    census_2025_path, movers_path, out_2025, year=2025\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4f89a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-movers HH_ID count: 2214\n",
      "[2024] Total rows: 32972 | Subset rows: 2214 | Unique HH_ID: 2214\n",
      "Saved: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2024_household_chn_nonmovers.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "nonmovers_path = os.path.join(DATA_PATH, \"nonmoversd.csv\")\n",
    "census_2024_path = os.path.join(with_chn_path, \"census2024_household_chn.csv\")\n",
    "\n",
    "if not os.path.exists(nonmovers_path):\n",
    "    raise FileNotFoundError(f\"Non-movers file not found: {nonmovers_path}\")\n",
    "\n",
    "if not os.path.exists(census_2024_path):\n",
    "    raise FileNotFoundError(f\"Census 2024 file not found: {census_2024_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load non-mover HH_IDs\n",
    "# -----------------------------\n",
    "nonmovers_df = pd.read_csv(nonmovers_path)\n",
    "\n",
    "if \"HH_ID\" not in nonmovers_df.columns:\n",
    "    raise ValueError(\"nonmoversd.csv is missing required column: HH_ID\")\n",
    "\n",
    "nonmovers_ids = (\n",
    "    pd.to_numeric(nonmovers_df[\"HH_ID\"], errors=\"coerce\")\n",
    "      .dropna()\n",
    "      .astype(int)\n",
    "      .drop_duplicates()\n",
    ")\n",
    "\n",
    "nonmovers_set = set(nonmovers_ids.tolist())\n",
    "\n",
    "print(\"Non-movers HH_ID count:\", len(nonmovers_set))\n",
    "\n",
    "# -----------------------------\n",
    "# Load 2024 census + subset\n",
    "# -----------------------------\n",
    "census_2024 = pd.read_csv(census_2024_path)\n",
    "\n",
    "if \"HH_ID\" not in census_2024.columns:\n",
    "    raise ValueError(\"[2024] Census file missing required column: HH_ID\")\n",
    "\n",
    "hh_id_num = pd.to_numeric(census_2024[\"HH_ID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "subset_2024_nonmovers = census_2024[\n",
    "    hh_id_num.isin(nonmovers_set)\n",
    "].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Save subset\n",
    "# -----------------------------\n",
    "out_path = os.path.join(\n",
    "    with_chn_path, \"census2024_household_chn_nonmovers.csv\"\n",
    ")\n",
    "\n",
    "subset_2024_nonmovers.to_csv(out_path, index=False)\n",
    "\n",
    "print(\n",
    "    \"[2024] Total rows:\", len(census_2024),\n",
    "    \"| Subset rows:\", len(subset_2024_nonmovers),\n",
    "    \"| Unique HH_ID:\", subset_2024_nonmovers[\"HH_ID\"].nunique()\n",
    ")\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfa5d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 CHN HH_ID count: 6814\n",
      "[2022] Total rows: 32972 | Subset rows: 6814 | Unique HH_ID: 6814\n",
      "Saved: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Microsimulations\\with_chn\\census2022_household_chn_from_2021chn.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "chn2021_path = os.path.join(DATA_PATH, \"2021chnhouseholds.csv\")\n",
    "census_2022_path = os.path.join(with_chn_path, \"census2022_household_chn.csv\")\n",
    "\n",
    "if not os.path.exists(chn2021_path):\n",
    "    raise FileNotFoundError(f\"2021 CHN file not found: {chn2021_path}\")\n",
    "\n",
    "if not os.path.exists(census_2022_path):\n",
    "    raise FileNotFoundError(f\"Census 2022 file not found: {census_2022_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load 2021 CHN HH_IDs\n",
    "# -----------------------------\n",
    "chn2021_df = pd.read_csv(chn2021_path)\n",
    "\n",
    "if \"HH_ID\" not in chn2021_df.columns:\n",
    "    raise ValueError(\"2021chnhouseholds.csv is missing required column: HH_ID\")\n",
    "\n",
    "chn2021_ids = (\n",
    "    pd.to_numeric(chn2021_df[\"HH_ID\"], errors=\"coerce\")\n",
    "      .dropna()\n",
    "      .astype(int)\n",
    "      .drop_duplicates()\n",
    ")\n",
    "\n",
    "chn2021_set = set(chn2021_ids.tolist())\n",
    "\n",
    "print(\"2021 CHN HH_ID count:\", len(chn2021_set))\n",
    "\n",
    "# -----------------------------\n",
    "# Load 2022 census + subset\n",
    "# -----------------------------\n",
    "census_2022 = pd.read_csv(census_2022_path)\n",
    "\n",
    "if \"HH_ID\" not in census_2022.columns:\n",
    "    raise ValueError(\"[2022] Census file missing required column: HH_ID\")\n",
    "\n",
    "hh_id_num_2022 = pd.to_numeric(\n",
    "    census_2022[\"HH_ID\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "\n",
    "subset_2022_from_2021chn = census_2022[\n",
    "    hh_id_num_2022.isin(chn2021_set)\n",
    "].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Save subset\n",
    "# -----------------------------\n",
    "out_path = os.path.join(\n",
    "    with_chn_path, \"census2022_household_chn_from_2021chn.csv\"\n",
    ")\n",
    "\n",
    "subset_2022_from_2021chn.to_csv(out_path, index=False)\n",
    "\n",
    "print(\n",
    "    \"[2022] Total rows:\", len(census_2022),\n",
    "    \"| Subset rows:\", len(subset_2022_from_2021chn),\n",
    "    \"| Unique HH_ID:\", subset_2022_from_2021chn[\"HH_ID\"].nunique()\n",
    ")\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55755947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CensusH path: C:/Users/mgordon/OneDrive - Financial Accountability Office of Ontario/FA2404 Housing and Homelessness Update/Data\\Statistics Canada\\Census 2021\\Hierarchical\\censush.csv exists? True\n"
     ]
    }
   ],
   "source": [
    "censush_path = os.path.join(\n",
    "    DATA_PATH,\n",
    "    \"Statistics Canada\",\n",
    "    \"Census 2021\",\n",
    "    \"Hierarchical\",\n",
    "    \"censush.csv\"\n",
    ")\n",
    "\n",
    "print(\"CensusH path:\", censush_path, \"exists?\", os.path.exists(censush_path))\n",
    "\n",
    "if not os.path.exists(censush_path):\n",
    "    raise FileNotFoundError(f\"censush.csv not found: {censush_path}\")\n",
    "\n",
    "censush = pd.read_csv(censush_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df187a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after PR==35 filter: 139734\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGEGRP",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weighted_population",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "unweighted_n",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "share",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "607af02d-0852-4fda-af89-34e4e72b14a0",
       "rows": [
        [
         "0",
         "1",
         "1333344.9955818378",
         "13278",
         "0.09502340160590837"
        ],
        [
         "1",
         "2",
         "707241.2113181867",
         "7043",
         "0.05040290838307069"
        ],
        [
         "2",
         "3",
         "708747.4754342982",
         "7058",
         "0.05051025519916413"
        ],
        [
         "3",
         "4",
         "797717.4758926133",
         "7944",
         "0.056850873803083"
        ],
        [
         "4",
         "5",
         "886486.6411354468",
         "8828",
         "0.0631771794981894"
        ],
        [
         "5",
         "6",
         "933381.6639503827",
         "9295",
         "0.06651924370589835"
        ],
        [
         "6",
         "7",
         "874938.6162452593",
         "8713",
         "0.06235418724147308"
        ],
        [
         "7",
         "8",
         "824328.1419439152",
         "8209",
         "0.05874733422073367"
        ],
        [
         "8",
         "9",
         "827742.3406071011",
         "8243",
         "0.05899065367054546"
        ],
        [
         "9",
         "10",
         "880160.3318477789",
         "8765",
         "0.06272632287059698"
        ],
        [
         "10",
         "11",
         "1924704.2875671852",
         "19167",
         "0.1371677616041908"
        ],
        [
         "11",
         "12",
         "1441796.0119418607",
         "14358",
         "0.10275237236463566"
        ],
        [
         "12",
         "13",
         "975356.2239860212",
         "9713",
         "0.06951064164770206"
        ],
        [
         "13",
         "88",
         "915808.5825957494",
         "9120",
         "0.06526686418480827"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 14
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEGRP</th>\n",
       "      <th>weighted_population</th>\n",
       "      <th>unweighted_n</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.333345e+06</td>\n",
       "      <td>13278</td>\n",
       "      <td>0.095023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.072412e+05</td>\n",
       "      <td>7043</td>\n",
       "      <td>0.050403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.087475e+05</td>\n",
       "      <td>7058</td>\n",
       "      <td>0.050510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.977175e+05</td>\n",
       "      <td>7944</td>\n",
       "      <td>0.056851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.864866e+05</td>\n",
       "      <td>8828</td>\n",
       "      <td>0.063177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9.333817e+05</td>\n",
       "      <td>9295</td>\n",
       "      <td>0.066519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>8.749386e+05</td>\n",
       "      <td>8713</td>\n",
       "      <td>0.062354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8.243281e+05</td>\n",
       "      <td>8209</td>\n",
       "      <td>0.058747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8.277423e+05</td>\n",
       "      <td>8243</td>\n",
       "      <td>0.058991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>8.801603e+05</td>\n",
       "      <td>8765</td>\n",
       "      <td>0.062726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.924704e+06</td>\n",
       "      <td>19167</td>\n",
       "      <td>0.137168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.441796e+06</td>\n",
       "      <td>14358</td>\n",
       "      <td>0.102752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>9.753562e+05</td>\n",
       "      <td>9713</td>\n",
       "      <td>0.069511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>88</td>\n",
       "      <td>9.158086e+05</td>\n",
       "      <td>9120</td>\n",
       "      <td>0.065267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGEGRP  weighted_population  unweighted_n     share\n",
       "0        1         1.333345e+06         13278  0.095023\n",
       "1        2         7.072412e+05          7043  0.050403\n",
       "2        3         7.087475e+05          7058  0.050510\n",
       "3        4         7.977175e+05          7944  0.056851\n",
       "4        5         8.864866e+05          8828  0.063177\n",
       "5        6         9.333817e+05          9295  0.066519\n",
       "6        7         8.749386e+05          8713  0.062354\n",
       "7        8         8.243281e+05          8209  0.058747\n",
       "8        9         8.277423e+05          8243  0.058991\n",
       "9       10         8.801603e+05          8765  0.062726\n",
       "10      11         1.924704e+06         19167  0.137168\n",
       "11      12         1.441796e+06         14358  0.102752\n",
       "12      13         9.753562e+05          9713  0.069511\n",
       "13      88         9.158086e+05          9120  0.065267"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Basic checks\n",
    "# -----------------------------\n",
    "required = {\"PP_ID\", \"AGEGRP\", \"WEIGHT\", \"PR\"}\n",
    "missing = required - set(censush.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"censush missing columns: {missing}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Filter: Ontario only (PR == 35)\n",
    "# -----------------------------\n",
    "censush_on = censush[censush[\"PR\"] == 35].copy()\n",
    "\n",
    "print(\"Rows after PR==35 filter:\", len(censush_on))\n",
    "\n",
    "# -----------------------------\n",
    "# Drop missing AGEGRP / WEIGHT\n",
    "# -----------------------------\n",
    "censush2 = censush_on.dropna(subset=[\"AGEGRP\", \"WEIGHT\"]).copy()\n",
    "\n",
    "# Ensure WEIGHT is numeric\n",
    "censush2[\"WEIGHT\"] = pd.to_numeric(censush2[\"WEIGHT\"], errors=\"coerce\")\n",
    "censush2 = censush2.dropna(subset=[\"WEIGHT\"])\n",
    "\n",
    "# -----------------------------\n",
    "# Weighted age distribution\n",
    "# -----------------------------\n",
    "age_dist = (\n",
    "    censush2\n",
    "    .groupby(\"AGEGRP\", as_index=False)\n",
    "    .agg(\n",
    "        weighted_population=(\"WEIGHT\", \"sum\"),\n",
    "        unweighted_n=(\"PP_ID\", \"nunique\")\n",
    "    )\n",
    ")\n",
    "\n",
    "age_dist[\"share\"] = (\n",
    "    age_dist[\"weighted_population\"] /\n",
    "    age_dist[\"weighted_population\"].sum()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Sort if AGEGRP is numeric-like\n",
    "# -----------------------------\n",
    "age_dist[\"AGEGRP_sort\"] = pd.to_numeric(age_dist[\"AGEGRP\"], errors=\"coerce\")\n",
    "age_dist = age_dist.sort_values(\n",
    "    [\"AGEGRP_sort\", \"AGEGRP\"]\n",
    ").drop(columns=[\"AGEGRP_sort\"])\n",
    "\n",
    "age_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fdf3a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGEGRP\tweighted_population\tunweighted_n\tshare_pct\n",
      "1\t1333344.9955818378\t13278\t9.5\n",
      "2\t707241.2113181867\t7043\t5.04\n",
      "3\t708747.4754342982\t7058\t5.05\n",
      "4\t797717.4758926133\t7944\t5.69\n",
      "5\t886486.6411354468\t8828\t6.32\n",
      "6\t933381.6639503827\t9295\t6.65\n",
      "7\t874938.6162452593\t8713\t6.24\n",
      "8\t824328.1419439152\t8209\t5.87\n",
      "9\t827742.3406071011\t8243\t5.9\n",
      "10\t880160.3318477789\t8765\t6.27\n",
      "11\t1924704.2875671852\t19167\t13.72\n",
      "12\t1441796.0119418607\t14358\t10.28\n",
      "13\t975356.2239860212\t9713\t6.95\n",
      "88\t915808.5825957494\t9120\t6.53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Format for Excel copy-paste\n",
    "excel_ready = age_dist.copy()\n",
    "\n",
    "# Optional: percent as %\n",
    "excel_ready[\"share_pct\"] = (excel_ready[\"share\"] * 100).round(2)\n",
    "excel_ready = excel_ready.drop(columns=[\"share\"])\n",
    "\n",
    "# Print as tab-delimited text\n",
    "print(excel_ready.to_csv(sep=\"\\t\", index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20dce007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weighted population (PR = 35): 14031754.00004763\n"
     ]
    }
   ],
   "source": [
    "total_weight_on = censush2[\"WEIGHT\"].sum()\n",
    "\n",
    "print(\"Total weighted population (PR = 35):\", total_weight_on)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
